{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000de3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "train_data=pd.read_csv(\"Finetune_data_125.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6aec4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicators                     (Select from drop-down list)</th>\n",
       "      <th>Description Simplified</th>\n",
       "      <th>Geographic Coverage</th>\n",
       "      <th>Format</th>\n",
       "      <th>Spatial Resolution</th>\n",
       "      <th>Temporal Resolution</th>\n",
       "      <th>Temporal Extent</th>\n",
       "      <th>Latency</th>\n",
       "      <th>Source/Link</th>\n",
       "      <th>Project</th>\n",
       "      <th>Data Visualization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food Availability</td>\n",
       "      <td>The Global Food Security-support Analysis Data...</td>\n",
       "      <td>Europe, Asia</td>\n",
       "      <td>GeoTIFF</td>\n",
       "      <td>30m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 to 2016-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.5067/MEaSUREs/GFSAD/GFSAD30...</td>\n",
       "      <td>MEaSUREs - Making Earth System Data Records fo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Food Availability</td>\n",
       "      <td>The Global Food Security-support Analysis Data...</td>\n",
       "      <td>South America</td>\n",
       "      <td>GeoTIFF</td>\n",
       "      <td>30m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 to 2016-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.5067/MEaSUREs/GFSAD/GFSAD30...</td>\n",
       "      <td>MEaSUREs - Making Earth System Data Records fo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food Availability</td>\n",
       "      <td>The Famine Early Warning Systems Network (FEWS...</td>\n",
       "      <td>Global</td>\n",
       "      <td>Shapefile</td>\n",
       "      <td>Varies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Varies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://fews.net/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urban Flooding</td>\n",
       "      <td>The Global Flood Hazard Frequency and Distribu...</td>\n",
       "      <td>Global</td>\n",
       "      <td>ASCII</td>\n",
       "      <td>0.0417 degrees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985-01-01 to 2003-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7927/H4668B3D</td>\n",
       "      <td>NDH - Natural Disaster Hotspots</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disasters</td>\n",
       "      <td>The ARIA (Advanced Rapid Imaging and Analysis)...</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>KML</td>\n",
       "      <td>30 meters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-25, 2017-09-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://appliedsciences.nasa.gov/our-impact/ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Indicators                     (Select from drop-down list)  \\\n",
       "0                                  Food Availability            \n",
       "1                                  Food Availability            \n",
       "2                                  Food Availability            \n",
       "3                                     Urban Flooding            \n",
       "4                                          Disasters            \n",
       "\n",
       "                              Description Simplified Geographic Coverage  \\\n",
       "0  The Global Food Security-support Analysis Data...        Europe, Asia   \n",
       "1  The Global Food Security-support Analysis Data...       South America   \n",
       "2  The Famine Early Warning Systems Network (FEWS...              Global   \n",
       "3  The Global Flood Hazard Frequency and Distribu...              Global   \n",
       "4  The ARIA (Advanced Rapid Imaging and Analysis)...         Puerto Rico   \n",
       "\n",
       "      Format Spatial Resolution Temporal Resolution           Temporal Extent  \\\n",
       "0    GeoTIFF                30m                 NaN  2013-01-01 to 2016-12-31   \n",
       "1    GeoTIFF                30m                 NaN  2013-01-01 to 2016-12-31   \n",
       "2  Shapefile             Varies                 NaN                    Varies   \n",
       "3      ASCII     0.0417 degrees                 NaN  1985-01-01 to 2003-12-31   \n",
       "4        KML          30 meters                 NaN    2017-03-25, 2017-09-21   \n",
       "\n",
       "  Latency                                        Source/Link  \\\n",
       "0     NaN  https://doi.org/10.5067/MEaSUREs/GFSAD/GFSAD30...   \n",
       "1     NaN  https://doi.org/10.5067/MEaSUREs/GFSAD/GFSAD30...   \n",
       "2     NaN                                  https://fews.net/   \n",
       "3     NaN                   https://doi.org/10.7927/H4668B3D   \n",
       "4     NaN  https://appliedsciences.nasa.gov/our-impact/ne...   \n",
       "\n",
       "                                             Project  Data Visualization  \n",
       "0  MEaSUREs - Making Earth System Data Records fo...               False  \n",
       "1  MEaSUREs - Making Earth System Data Records fo...               False  \n",
       "2                                                NaN                True  \n",
       "3                    NDH - Natural Disaster Hotspots                True  \n",
       "4                                                NaN                True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a79e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data={}\n",
    "for each_data in train_data.iterrows():\n",
    "    final_data[each_data[1][8]]={\"Indicators\":each_data[1][0],\n",
    "              \"Description\":each_data[1][1],\n",
    "              \"Geographic_Coverage\":each_data[1][2],\n",
    "              \"Format\":each_data[1][3],\n",
    "              \"Spatial_Resolution\":each_data[1][4],\n",
    "              \"Temporal_Resolution\":each_data[1][5],\n",
    "              \"Temporal_Extent\":each_data[1][6],\n",
    "              \"Latency\":each_data[1][7],\n",
    "                \"Project\":each_data[1][9],\n",
    "                \"Data_Visualization\":each_data[1][10]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cd9d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url,value in final_data.items():\n",
    "    response=requests.get(url)\n",
    "    html_page = response.text\n",
    "    soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "    text=soup.get_text()\n",
    "    text = re.sub(r'[\\t\\n\\r\\f\\v]+', '', text)\n",
    "    text=re.sub(r'[^\\w\\s]', '', text)\n",
    "    final_data[url][\"text\"]=text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1beef6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7a6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SYSTEM_PROMPT =\"Extract metadata and entities details accurately from my requests.\" + \"Metadata extraction for Indicators should clearly be one of the element in the list ['Disasters','Human Dimensions','Food Availability','Health & Air Quality','Water Availability', 'Extreme Heat','Urban Flooding','Climate']. Do not create new element for indicators \" + \"Make sure the following fields follow the following regex pattern\"+\"Spatial_Resolution: ^(\\d+(\\.\\d+)? [a-zA-Z]+|varies|N/A)$\"+\"Temporal_Resolution: ^(\\d+(\\.\\d+)? [a-zA-Z]+|N/A|varies|weekly|monthly|daily|yearly|varies-multiple datasets included|Daily < Weekly|Hourly < Daily|Weekly < Monthly|Monthly < Yearly|1 minute)$\"+\"Temporal_Extent: ^(\\d{4}-\\d{2}-\\d{2} to present|present|\\d{4}-\\d{2}-\\d{2} (?:to|until) present|\\d{4}-\\d{2}-\\d{2} to \\d{4}-\\d{2}-\\d{2}|varies(?:- multiple datasets (?:included|available))?)$\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ec79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "for url,value in final_data.items():\n",
    "#     data={\"messages\": [{\"role\": \"system\", \"content\":_SYSTEM_PROMPT},{\"role\": \"user\", \"content\": f'{value[\"text\"]}'}, {\"role\": \"assistant\", \"content\": {\"Indicators\":value[\"Indicators\"],\"Description\":value[\"Description\"],\"Geographic_Coverage\":value[\"Geographic_Coverage\"], \"Format\":value[\"Format\"],\"Spatial_Resolution\":value[\"Spatial_Resolution\"],\"Temporal_Resolution\":value[\"Temporal_Resolution\"],\"Temporal_Extent\":value[\"Temporal_Extent\"],\"Latency\":value[\"Latency\"],\"Project\":value[\"Project\"],\"Data_Visualization\":value[\"Data_Visualization\"]}}]}\n",
    "    output_content={\"Indicators\":value[\"Indicators\"],\"Description\":value[\"Description\"],\"Geographic_Coverage\":value[\"Geographic_Coverage\"], \"Format\":value[\"Format\"],\"Spatial_Resolution\":value[\"Spatial_Resolution\"],\"Temporal_Resolution\":value[\"Temporal_Resolution\"],\"Temporal_Extent\":value[\"Temporal_Extent\"],\"Latency\":value[\"Latency\"],\"Project\":value[\"Project\"],\"Data_Visualization\":value[\"Data_Visualization\"]}\n",
    "    output_content=str(output_content)\n",
    "    data={\"messages\": [{\"role\": \"system\", \"content\":_SYSTEM_PROMPT},{\"role\": \"user\", \"content\":f'{value[\"text\"]}'}, {\"role\": \"assistant\", \"content\": output_content}]}\n",
    "    train_data.append(data)\n",
    "    \n",
    "# with open(\"train_data_125.jsonl\", 'w') as jsonl_file:\n",
    "#     for record in train_data:\n",
    "#         jsonl_file.write(json.dumps(record) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11b288f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_data_125=list(final_data.keys())\n",
    "train_data_125=[i.strip() for i in train_data_125]\n",
    "train_data_125=list(set(train_data_125))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "202176f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"train_data/train_125_urls.pkl\",'wb') as file:\n",
    "#     pickle.dump(train_data_125,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792ef37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install -e .\n",
    "# !pip install spacy\n",
    "# !python3 -m spacy download en_core_web_lg\n",
    "# !pip install pandas\n",
    "# !pip install openpyxl\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1cf745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': \"Extract metadata and entities details accurately from my requests.Metadata extraction for Indicators should clearly be one of the element in the list ['Disasters','Human Dimensions','Food Availability','Health & Air Quality','Water Availability', 'Extreme Heat','Urban Flooding','Climate']. Do not create new element for indicators Make sure the following fields follow the following regex patternSpatial_Resolution: ^(\\\\d+(\\\\.\\\\d+)? [a-zA-Z]+|varies|N/A)$Temporal_Resolution: ^(\\\\d+(\\\\.\\\\d+)? [a-zA-Z]+|N/A|varies|weekly|monthly|daily|yearly|varies-multiple datasets included|Daily < Weekly|Hourly < Daily|Weekly < Monthly|Monthly < Yearly|1 minute)$Temporal_Extent: ^(\\\\d{4}-\\\\d{2}-\\\\d{2} to present|present|\\\\d{4}-\\\\d{2}-\\\\d{2} (?:to|until) present|\\\\d{4}-\\\\d{2}-\\\\d{2} to \\\\d{4}-\\\\d{2}-\\\\d{2}|varies(?:- multiple datasets (?:included|available))?)$\"}, {'role': 'user', 'content': '  LP DAAC  GFSAD30EUCEARUMECEHomeAboutAbout LP DAAC                                                                                                    News Archive                                                                                                    DataGet Started with Data                                                                                                    Search Data Catalog                                                                                                    Data Citations and Policies                                                                                                    View All DataToolsAppEEARSData PoolData Prep ScriptsNASA Earthdata SearchUSGS EarthExplorerView All ToolsResourcesData in Action                                                                                                    ELearning                                                                                                    Podcasts                                                                                                    Outreach Materials                                                                                                    Publications Table                                                                                                    FAQs                                                                                                    View All ResourcesContactContact Information                                                                                                    Submit Data                                                                                                    General Site SearchGFSAD30EUCEARUMECE v001Global Food Securitysupport Analysis Data GFSAD Cropland Extent 2015 Europe Central Asia Russia Middle East 30 m PI Prasad ThenkabailDocumentationUsing the DataAccess DataCitationRelated ProductsHomepageDataSearch Data CatalogGFSAD30EUCEARUMECEv001DescriptionThe NASA Making Earth System Data Records for Use in Research Environments MEaSUREs Global Food Securitysupport Analysis Data GFSAD data product provides cropland extent data over Europe Central Asia Russia and the Middle East for nominal year 2015 at 30 meter resolution GFSAD30EUCEARUMECE The monitoring of global cropland extent is critical for policymaking and provides important baseline data that are used in many agricultural cropland studies pertaining to water sustainability and food security The GFSAD30EUCEARUMECE product uses a pixelbased supervised random forest machine learning algorithm to retrieve cropland extent from a combination of Landsat 7 Enhanced Thematic Mapper ETM Landsat 8 Operational Land Imager OLI data and elevation derived from the Shuttle Radar Topography Mission SRTM Version 3 data products Each GFSAD30EUCEARUMECE GeoTIFF file contains a cropland extent layer that defines areas of cropland noncropland and water bodies over a 10 by 10 arearead moreCharacteristicsCollection and GranuleCollectionCharacteristicDescriptionCollectionMEaSUREs GFSADDOI105067MEaSUREsGFSADGFSAD30EUCEARUMECE001File Size2929 MBTemporal ResolutionMultiYearTemporal Extent20130101 to 20161231Spatial ExtentEurope Central Asia Russia and the Middle EastCoordinate SystemGeographic Latitude and LongitudeDatumWorld Geodetic System WGS84File FormatGeoTIFFGeographic Dimensions10 x 10GranuleCharacteristicDescriptionNumber of Science Dataset SDS Layers1ColumnsRows37115 x 37375Pixel Size30 mLayers  VariablesSDS NameDescriptionUnitsData TypeFill ValueNo Data ValueValid RangeScale FactorBand\\xa01Cropland\\xa0Extent for Europe\\xa0Central Asia Russia and the Middle East defined with three classesNA8bit unsigned integerNANA0 to 2NACropland Extent Class DescriptionsClass LabelNameDescription0WaterWater bodies1NonCroplandNonCropland areas2CroplandCropland areasFilename convention GFSAD30EUCEARUMECE _2015_GridTile_001_ProcessingDateYYYYJJJHHMMSStifProduct QualityProduct Quality information can be found on page 19 of the Algorithm Theoretical Basis Document ATBDKnown IssuesKnown issues including constraints and limitations are provided on page 20 of the ATBDAbout the imageGlobal Food Securitysupport Analysis Data GFSAD Cropland Extent data from the GFSAD30EUCEARUMECE product over eastern Europe 2015View fullsize imageDocumentationUser GuideAlgorithm Theoretical Basis Document ATBDSource CodeUsing the DataELearningData Citation Tips from NASAs Land Processes DAACPublicationsView research publications that used these dataEarthdata ForumJoin the data discussion over on the Earthdata ForumAccess DataToolFunctionalityDescriptionDownload DataData PoolDirect DownloadThe Data Pool is the publicly available portion of the LP DAAC online holdings Data Pool provides NASA Earthdata SearchBrowse Image Preview Direct Download Order Search SubsetEarthdata Search combines the latest EOSDIS service offerings with user experience research and eUSGS EarthExplorerBrowse Image Preview SearchThe EarthExplorer EE user interface developed by the United States Geological Survey USGS proDAAC2Disk UtilityDirect DownloadThe LP DAAC2Disk download manager allows users to simplify the search and HTTPS download process ofCitationDOI 105067MEaSUREsGFSADGFSAD30EUCEARUMECE001Select a citation styleAPAChicago                       Copy Citation                Related ProductsView data products that are related to this productAbout                                About the LP DAAC                                                                                            News Archive                                                            Data                                View All Data                                                                                            Get Started with Data                                                                                            Collection Overviews                                                                                            Workflow Examples                                                                                            Search Data Catalog                                                                                            Data Citation and Policies                                                            Tools                                AppEEARS                                                                                            Data Pool                                                                                            DAAC2Disk Utility                                                                                            NASA Earthdata Search                                                                                            USGS EarthExplorer                                                                                            View All Tools                                                            Resources                                ELearning                                                                                            FAQs                                                                                            Data in Action                                                                                            Outreach Materials                                                                                            View All Resources                                                            Contact                                Contact LP DAAC                                                                                            Submit Data                                                                                            Earthdata Forum                                                                                                            DOI Privacy PolicyLegalAccessibilityContact USGSUS Department of the InteriorDOI Inspector GeneralWhite HouseEGovNo Fear ActFOIA47914 252nd Street                               Sioux Falls SD 571980001                            Voice 6055946116                              Toll Free 8665733222                             Fax 6055946963lpdaacusgsgov'}, {'role': 'assistant', 'content': \"{'Indicators': 'Food Availability', 'Description': 'The Global Food Security-support Analysis Data (GFSAD) Cropland Extent 2015 Europe, Central Asia, Russia, Middle East product 30 m V001 dataset provides cropland extent data for Europe, Central Asia, Russia, and the Middle East for the year 2015. These data may be useful in agricultural cropland studies related to water sustainability and food security.', 'Geographic_Coverage': 'Europe, Asia', 'Format': 'GeoTIFF', 'Spatial_Resolution': '30m', 'Temporal_Resolution': nan, 'Temporal_Extent': '2013-01-01 to 2016-12-31', 'Latency': nan, 'Project': 'MEaSUREs - Making Earth System Data Records for Use in Research Environments', 'Data_Visualization': False}\"}]}\n"
     ]
    }
   ],
   "source": [
    "urls=train_data[0]\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee01d808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.28.1)\n",
      "Collecting openai\n",
      "  Using cached openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.1\n",
      "    Uninstalling openai-0.28.1:\n",
      "      Successfully uninstalled openai-0.28.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "larch 0.0.2a0 requires openai==0.28.1, but you have openai 1.12.0 which is incompatible.\n",
      "instructor 0.2.9 requires openai<0.29.0,>=0.28.0, but you have openai 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed openai-1.12.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b19ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #30, 50, 100,115\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# client.files.create(\n",
    "#   file=open(\"train_data_125.jsonl\", \"rb\"),\n",
    "#   purpose=\"fine-tune\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f70cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-9bdVfZZoDv5fuRXndGkWyAcK', created_at=1707930798, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=10, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-KVpMEM9Q8Xm2pc8YuAMYw8r3', result_files=[], status='validating_files', trained_tokens=None, training_file='file-l5p3xkTCqGY9GNAWTwj5PPaj', validation_file=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-l5p3xkTCqGY9GNAWTwj5PPaj\", \n",
    "  model=\"gpt-3.5-turbo-1106\", \n",
    "  hyperparameters={\n",
    "    \"n_epochs\":10\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16ee902a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-9bdVfZZoDv5fuRXndGkWyAcK', created_at=1707930798, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-KVpMEM9Q8Xm2pc8YuAMYw8r3', result_files=[], status='running', trained_tokens=None, training_file='file-l5p3xkTCqGY9GNAWTwj5PPaj', validation_file=None)], object='list', has_more=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c01a436d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-9bdVfZZoDv5fuRXndGkWyAcK', created_at=1707930798, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-1106:nasa::8sDqIEsU', finished_at=1707933614, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-KVpMEM9Q8Xm2pc8YuAMYw8r3', result_files=['file-92wcOk9XKYFmiUjQGX9pJ4cF'], status='succeeded', trained_tokens=1745180, training_file='file-l5p3xkTCqGY9GNAWTwj5PPaj', validation_file=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(\"ftjob-9bdVfZZoDv5fuRXndGkWyAcK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f211bf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/rajashreedahal/Desktop/Metadata_Finetuning/larch\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pgvector==0.2.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (0.2.4)\n",
      "Requirement already satisfied: langchain==0.0.304 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (0.0.304)\n",
      "Requirement already satisfied: psycopg2-binary==2.9.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (2.9.9)\n",
      "Requirement already satisfied: pytest==7.4.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (7.4.4)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (4.66.1)\n",
      "Requirement already satisfied: pynequa==0.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (0.2.0)\n",
      "Requirement already satisfied: loguru==0.7.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (0.7.2)\n",
      "Requirement already satisfied: instructor==0.2.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (0.2.9)\n",
      "Requirement already satisfied: deepdiff==6.6.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (6.6.1)\n",
      "Requirement already satisfied: pytest-cov==4.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (4.1.0)\n",
      "Requirement already satisfied: tiktoken==0.5.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (0.5.2)\n",
      "Requirement already satisfied: openai==0.28.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (0.28.1)\n",
      "Requirement already satisfied: rapidfuzz==3.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (3.4.0)\n",
      "Requirement already satisfied: joblib==1.3.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (1.3.2)\n",
      "Requirement already satisfied: langchain-experimental==0.0.23 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from larch==0.0.2a0) (0.0.23)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deepdiff==6.6.1->larch==0.0.2a0) (4.1.0)\n",
      "Requirement already satisfied: docstring-parser<0.16,>=0.15 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from instructor==0.2.9->larch==0.0.2a0) (0.15)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from instructor==0.2.9->larch==0.0.2a0) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from instructor==0.2.9->larch==0.0.2a0) (2.6.1)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (2.8.4)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (0.0.86)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (8.2.2)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (1.24.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (2.0.18)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (4.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (3.8.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (2.31.0)\n",
      "Requirement already satisfied: anyio<4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (3.6.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (1.33)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain==0.0.304->larch==0.0.2a0) (0.5.9)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest==7.4.4->larch==0.0.2a0) (23.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest==7.4.4->larch==0.0.2a0) (1.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest==7.4.4->larch==0.0.2a0) (1.4.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest==7.4.4->larch==0.0.2a0) (2.0.1)\n",
      "Requirement already satisfied: iniconfig in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest==7.4.4->larch==0.0.2a0) (2.0.0)\n",
      "Requirement already satisfied: coverage[toml]>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytest-cov==4.1.0->larch==0.0.2a0) (6.4.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tiktoken==0.5.2->larch==0.0.2a0) (2023.8.8)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.304->larch==0.0.2a0) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.304->larch==0.0.2a0) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.304->larch==0.0.2a0) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.304->larch==0.0.2a0) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.304->larch==0.0.2a0) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.304->larch==0.0.2a0) (6.0.4)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.304->larch==0.0.2a0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.304->larch==0.0.2a0) (1.3.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.304->larch==0.0.2a0) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.304->larch==0.0.2a0) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.304->larch==0.0.2a0) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.304->larch==0.0.2a0) (2.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.2->instructor==0.2.9->larch==0.0.2a0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.2->instructor==0.2.9->larch==0.0.2a0) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.2->instructor==0.2.9->larch==0.0.2a0) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.304->larch==0.0.2a0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.304->larch==0.0.2a0) (2023.7.22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer<0.10.0,>=0.9.0->instructor==0.2.9->larch==0.0.2a0) (8.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.304->larch==0.0.2a0) (0.4.3)\n",
      "Building wheels for collected packages: larch\n",
      "  Building editable for larch (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for larch: filename=larch-0.0.2a0-0.editable-py3-none-any.whl size=14420 sha256=06f2af8ebec75ec1314f3f6955a0bbcccfbba4247ef4baa1ab4a3500dd2a8266\n",
      "  Stored in directory: /private/var/folders/m4/9_ydsvdn3b3d84rntrrsxm0h0000gn/T/pip-ephem-wheel-cache-1d0sznke/wheels/3a/98/39/46f8f1efc02842106044493327f82ab1f2c43a0a7f389a1df9\n",
      "Successfully built larch\n",
      "Installing collected packages: larch\n",
      "  Attempting uninstall: larch\n",
      "    Found existing installation: larch 0.0.2a0\n",
      "    Uninstalling larch-0.0.2a0:\n",
      "      Successfully uninstalled larch-0.0.2a0\n",
      "Successfully installed larch-0.0.2a0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.7.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.24.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (63.2.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (8.2.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting en-core-web-lg==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from en-core-web-lg==3.7.1) (3.7.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (63.2.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (23.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (6.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.24.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2023.7.22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e .\n",
    "!pip install spacy\n",
    "!python3 -m spacy download en_core_web_lg\n",
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4def28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_data/train_125_urls.pkl\",'rb') as file:\n",
    "    train_125_urls=pickle.load(file)\n",
    "\n",
    "train_125_urls=[i.strip() for i in train_125_urls]\n",
    "train_125_urls=list(set(train_125_urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7b6651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://doi.org/10.7927/0gdn-6y33',\n",
       " 'https://doi.org/10.7927/H40P0WXQ',\n",
       " 'https://disc.gsfc.nasa.gov/datacollection/ML2O3_NRT_005.html',\n",
       " 'https://doi.org/10.5067/FIRMS/VIIRS/VJ114IMGT_NRT.002',\n",
       " 'https://dx.doi.org/10.5067/GMSLM-TJ151',\n",
       " 'https://dx.doi.org/10.7927/d1x1-d702',\n",
       " 'https://aria-share.jpl.nasa.gov/',\n",
       " 'https://sedac.ciesin.columbia.edu/mapping/popgrid/',\n",
       " 'https://doi.org/10.7927/H4JW8BTT',\n",
       " 'https://doi.org/10.5067/Aura/OMI/DATA3008',\n",
       " 'https://dx.doi.org/10.5067/Aura/OMI/DATA3007',\n",
       " 'https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature',\n",
       " 'https://doi.org/10.7927/H40Z716C',\n",
       " 'https://doi.org/10.7927/H4S180F9',\n",
       " 'https://doi.org/10.7927/fx80-4n39',\n",
       " 'https://data.worldbank.org/indicator/EN.ATM.PM25.MC.M3?view=chart',\n",
       " 'https://ldas.gsfc.nasa.gov/fldas',\n",
       " 'https://dx.doi.org/10.7927/9ryj-6467',\n",
       " 'https://dx.doi.org/10.7927/3xxe-ap97',\n",
       " 'https://doi.org/10.5067/MEaSUREs/GFSAD/GFSAD30SACE.001',\n",
       " 'https://doi.org/10.5067/MEaSUREs/GFSAD/GFSAD30SEACE.001',\n",
       " 'https://doi.org/10.7927/H4N877QK',\n",
       " 'https://fews.net/',\n",
       " 'https://go.nasa.gov/2IDvag7',\n",
       " 'https://dx.doi.org/10.5067/ECOSTRESS/ECO2LSTE.001',\n",
       " 'https://disc.gsfc.nasa.gov/datacollection/ML2HNO3_NRT_005.html',\n",
       " 'https://dx.doi.org/10.5067/ASTER/AST_08.003',\n",
       " 'https://doi.org/10.7927/H4WS8R5B',\n",
       " 'https://doi.org/10.7927/H4P55KKF',\n",
       " 'https://dx.doi.org/10.5067/HLS/HLSS30.002',\n",
       " 'https://search.earthdata.nasa.gov/search?q=MOD21&fp=Terra',\n",
       " 'https://doi.org/10.7927/3xxe-ap97',\n",
       " 'https://doi.org/10.7927/H4T151KP',\n",
       " 'https://dx.doi.org/10.5067/HLS/HLSL30.002',\n",
       " 'https://arthurhou.pps.eosdis.nasa.gov/',\n",
       " 'https://doi.org/10.5067/Community/MuSLI/MSLSP30NA.011',\n",
       " 'http://www.tropomi.eu/data-products/uv-aerosol-index',\n",
       " 'https://search.earthdata.nasa.gov/search?fi=TROPOMI&fst0=Atmosphere&fsm0=Air%20Quality&fs10=Carbon%20Monoxide',\n",
       " 'https://doi.org/10.5067/MEaSUREs/GFSAD/GFSAD30EUCEARUMECE.001',\n",
       " 'https://search.earthdata.nasa.gov/search?q=VNP21&fi=VIIRS',\n",
       " 'https://sedac.ciesin.columbia.edu/data/collection/aqdh/sets/browse',\n",
       " 'https://dx.doi.org/10.5067/0WF4HAAZ0VHK',\n",
       " 'https://search.earthdata.nasa.gov/search?q=AERDB_D3&ok=AERDB_D3',\n",
       " 'https://doi.org/10.7927/rja8-8h89',\n",
       " 'https://doi.org/10.7927/H4HH6H08',\n",
       " 'https://doi.org/10.7927/H44F1NNF',\n",
       " 'https://search.earthdata.nasa.gov/search?q=V008&ok=V008&fi=MOPITT&fst0=Atmosphere&fsm0=Air%20Quality&fs10=Carbon%20Monoxide',\n",
       " 'https://doi.org/10.7927/H46M34XX',\n",
       " 'https://dx.doi.org/10.5067/TEMSC-3JC63',\n",
       " 'https://doi.org/10.7927/H4FF3Q9B',\n",
       " 'https://so2.gsfc.nasa.gov/no2/no2_index.html',\n",
       " 'https://search.earthdata.nasa.gov/search/granules?p=C1427459680-USGS_EROS&pg[0][v]=f&q=landsat%207&tl=1647148623.75!3!!',\n",
       " 'https://dx.doi.org/10.5067/ECTSM-MSL44',\n",
       " 'https://doi.org/10.5067/MEaSUREs/GFSAD/GFSAD30AUNZCNMOCE.001',\n",
       " 'https://search.earthdata.nasa.gov/search?q=AIRS3ST&fi=AIRS&fs10=Surface%20Temperature&fsm0=Atmospheric%20Temperature&fs20=Air%20Temperature&fst0=Atmosphere',\n",
       " 'https://lpdaac.usgs.gov/news/release-nasadem-data-products/',\n",
       " 'https://search.earthdata.nasa.gov/search?q=aerosol%20index%20OMAER&ok=aerosol%20index%20OMAER&fi=OMI&fst0=Atmosphere&fsm0=Aerosols',\n",
       " 'https://search.earthdata.nasa.gov/search?q=MOD04_3K&ok=MOD04_3K',\n",
       " 'https://doi.org/10.5067/Aura/OMI/DATA2017',\n",
       " 'https://doi.org/10.7927/H42V2D1C',\n",
       " 'https://dx.doi.org/10.7927/1z4r-ez63',\n",
       " 'https://doi.org/10.7927/H44T6G9K',\n",
       " 'https://dx.doi.org/10.3334/ORNLDAAC/1694',\n",
       " 'https://doi.org/10.7927/nj0x-8y67',\n",
       " 'https://doi.org/10.7927/zz3b-8y61',\n",
       " 'https://doi.org/10.7927/H4319SVC',\n",
       " 'https://nasa.maps.arcgis.com/home/webmap/viewer.html?webmap=f33be724f04b4b4c942edd0c9bd18f48',\n",
       " 'https://dx.doi.org/10.5067/ECTSD-MSL44',\n",
       " 'https://www.airnow.gov/index.cfm?action=airnow.international',\n",
       " 'https://svs.gsfc.nasa.gov/4658#:~:text=NASA%27s%20Black%20Marble%20night%20lights%20used%20to%20examine%20disaster%20recovery%20in%20Puerto%20Rico,-Visualizations%20by%20Kel&text=At%20night%2C%20Earth%20is%20lit,Puerto%20Rico%27s%20lights%20went%20out.',\n",
       " 'https://doi.org/10.7927/H4XS5S9Q',\n",
       " 'https://doi.org/10.7927/H4668B3D',\n",
       " 'https://dx.doi.org/10.5067/MODIS/MCD43GF.006',\n",
       " 'https://cmr.earthdata.nasa.gov/search/concepts/C2205556193-POCLOUD.html',\n",
       " 'https://search.earthdata.nasa.gov/search?fi=TROPOMI&fst0=Atmosphere&fsm0=Atmospheric%20Chemistry&fs10=Nitrogen%20Compounds',\n",
       " 'https://worldview.earthdata.nasa.gov/?p=geographic&l=VIIRS_SNPP_CorrectedReflectance_TrueColor(hidden),MODIS_Aqua_CorrectedReflectance_TrueColor(hidden),MODIS_Terra_CorrectedReflectance_TrueColor,MLS_N2O_46hPa_Night,MLS_N2O_46hPa_Day,Reference_Labels(hidden),Reference_Features(hidden),Coastlines&v=-92.7421875,-49.47803771636507,66.5859375,55.94678771636507',\n",
       " 'https://doi.org/10.7927/hn96-9703',\n",
       " 'https://visibleearth.nasa.gov/images/88078/scientists-improve-maps-of-subsidence-in-new-orleans?size=large',\n",
       " 'https://doi.org/10.7927/H4XW4GQ1',\n",
       " 'https://doi.org/10.5067/MEaSUREs/GFSAD/GFSAD30AFCE.001',\n",
       " 'https://search.earthdata.nasa.gov/search?q=merra-2&fs10=Surface%20Temperature&fsm0=Atmospheric%20Temperature&fs20=Air%20Temperature&fst0=Atmosphere',\n",
       " 'https://dx.doi.org/10.5067/ALTCY-TJA51',\n",
       " 'https://doi.org/10.7927/H4VD6WCT',\n",
       " 'https://doi.org/10.7927/H4ZK5DQS',\n",
       " 'https://gispub.epa.gov/airnow/index.html?tab=3',\n",
       " 'https://fluid.nccs.nasa.gov/wxmaps/',\n",
       " 'https://dx.doi.org/10.3334/ORNLDAAC/1564',\n",
       " 'https://search.earthdata.nasa.gov/search?q=AERDB_L2',\n",
       " 'https://dx.doi.org/10.5067/MODIS/MYD14.061',\n",
       " 'https://search.earthdata.nasa.gov/search?q=AIRX3std',\n",
       " 'https://sedac.ciesin.columbia.edu/data/collection/gpw-v4/sedac-hazards-mapper',\n",
       " 'https://dx.doi.org/10.5067/ECOSTRESS/ECO2CLD.001',\n",
       " 'https://search.earthdata.nasa.gov/search?m=-97.681640625!-20.25439453125!0!1!0!0%2C2&q=AIRS3ST&ok=AIRS3ST&fi=AIRS&fst0=Atmosphere&fs10=Tropospheric%20Ozone&fst1=Atmosphere&fst2=Atmosphere',\n",
       " 'https://doi.org/10.7927/H49P2ZKM',\n",
       " 'https://search.earthdata.nasa.gov/search?q=VNP21',\n",
       " 'https://doi.org/10.5067/MOQOVNHNERGG',\n",
       " 'https://doi.org/10.7927/fq7g-ny13',\n",
       " 'https://cmr.earthdata.nasa.gov/search/concepts/C2157848116-PODAAC.html',\n",
       " 'https://search.earthdata.nasa.gov/search?q=MOD11&fsm0=Surface%20Radiative%20Properties&fst0=Land%20Surface',\n",
       " 'https://doi.org/10.7927/9ryj-6467',\n",
       " 'https://storymaps.arcgis.com/stories/a3d0b0835b9e45b69f55e5ce94d84ddf',\n",
       " 'https://disc.gsfc.nasa.gov/datacollection/ML2CO_NRT_005.html',\n",
       " 'https://doi.org/10.7927/H4H70CRF',\n",
       " 'https://doi.org/10.7927/6s2a-9r49',\n",
       " 'https://appliedsciences.nasa.gov/our-impact/news/aria-damage-proxy-map-puerto-rico-after-hurricane-maria https://ghis.maps.arcgis.com/home/item.html?id=1ce3ccaacc6c4cd7b3b6cef4ea4980aa',\n",
       " 'https://doi.org/10.7927/d1x1-d702',\n",
       " 'https://search.earthdata.nasa.gov/search?q=AIRS3&ok=AIRS3&fi=AIRS&fst0=Atmosphere&fsm0=Air%20Quality&fs10=Carbon%20Monoxide',\n",
       " 'https://doi.org/10.5067/T4OW83T8EXDO',\n",
       " 'https://dx.doi.org/10.5067/QLW535AYJ498',\n",
       " 'https://doi.org/10.7927/cx02-2587',\n",
       " 'https://dx.doi.org/10.5067/GMSLT-FJPL1',\n",
       " 'https://maps.disasters.nasa.gov/arcgis/apps/opsdashboard/index.html#/a70a27ff74f94fa9a23123b58b3ee613',\n",
       " 'https://dx.doi.org/10.5067/ALTTS-TJA51',\n",
       " 'https://gpm.nasa.gov/data/directory',\n",
       " 'https://search.earthdata.nasa.gov/search?q=MAIAC&fi=MODIS&fst0=Atmosphere',\n",
       " 'https://search.earthdata.nasa.gov/search?q=AERDB_M3&ok=AERDB_M3',\n",
       " 'https://search.earthdata.nasa.gov/search?fi=OMI&fst0=Atmosphere&fsm0=Atmospheric%20Chemistry&fs10=Nitrogen%20Compounds&fs20=Nitrogen%20Dioxide',\n",
       " 'https://dx.doi.org/10.5067/MEASURES/SO2/DATA205',\n",
       " 'https://search.earthdata.nasa.gov/search?m=-0.0703125!0.140625!2!1!0!0%2C2&q=OMTO3&ok=OMTO3&fi=OMI&fst0=Atmosphere&fsm0=Air%20Quality&fs10=Tropospheric%20Ozone&fst1=Atmosphere&fst2=Atmosphere',\n",
       " 'https://doi.org/10.7927/H4HQ3WTH']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_125_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e765e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from larch.metadata import InstructorBasedOpenAIMetadataExtractor\n",
    "from larch.metadata.validators import WhitelistBasedMetadataValidator\n",
    "from larch.processors import PIIRemover, TextProcessingPipeline\n",
    "from larch.utils import load_whitelist\n",
    "\n",
    "text_processor = TextProcessingPipeline(\n",
    "    lambda x: re.sub(r\"\\$(?=\\w|\\n|\\()\", \" \", x).strip(),\n",
    "    lambda x: re.sub(r\"\\)(?=\\w|\\n|\\()\", \" \", x).strip(),\n",
    "    lambda x: re.sub(r\"\\#(?=\\w|\\n|\\()\", \" \", x).strip(),\n",
    "    lambda x: x.replace(\"\\t\", \" \").replace(\"!\", \" \").strip(),\n",
    "    PIIRemover()\n",
    ")\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from pydantic import BaseModel,constr,Field\n",
    "from typing import Literal\n",
    "\n",
    "class Environmental_Justice(BaseModel):\n",
    "    Indicators: Literal[\"Disasters\",\"Human Dimensions\",\"Food Availability\",\"Health & Air Quality\",\"Water Availability\", \"Extreme Heat\",\"Urban Flooding\",\"Climate\"]\n",
    "    Description: str\n",
    "    Geographic_Coverage: str =Field(pattern=r'')\n",
    "    Format: str\n",
    "    Spatial_Resolution: str = Field(pattern=r'^(\\d+(\\.\\d+)? [a-zA-Z]+|varies|N/A)$')\n",
    "    Temporal_Resolution: str = Field(pattern=r'^(\\d+(\\.\\d+)? [a-zA-Z]+|N/A|varies|weekly|monthly|daily|yearly|varies-multiple datasets included|Daily < Weekly|Hourly < Daily|Weekly < Monthly|Monthly < Yearly|1 minute)$')\n",
    "    Temporal_Extent: str = Field(pattern=r'^(\\d{4}-\\d{2}-\\d{2} to present|present|\\d{4}-\\d{2}-\\d{2} (?:to|until) present|\\d{4}-\\d{2}-\\d{2} to \\d{4}-\\d{2}-\\d{2}|varies(?:- multiple datasets (?:included|available))?)$')\n",
    "    Latency: str = Field(pattern=r'^\\d+(\\s*(Day|days|months|NRT))?$')\n",
    "    Project: str\n",
    "    Data_Visualization: bool\n",
    "\n",
    "\n",
    "    \n",
    "schema = Environmental_Justice\n",
    "sheet_names=[\"Water Availability - Cleaned\", \"Disasters (Disaster Recovery) -\", \n",
    " \"Food Availability - Cleaned\", \"Human Dimensions - Cleaned\", \"Urban Flooding - Cleaned\",\n",
    " \"Extreme Heat - CIP\",\"Climate (Climate Change) - CIP\",\"Health and Air Quality - CIP\"]\n",
    "used_urls=[]\n",
    "\n",
    "for each_sheet in sheet_names:\n",
    "    mapper = pd.read_excel(\"nasa_esds.xlsx\", sheet_name=[each_sheet])\n",
    "    res = {}\n",
    "    url_lists=[]\n",
    "    for field_key, value_df in mapper.items():\n",
    "        res[field_key] = {}\n",
    "        cols = value_df.columns\n",
    "        for i, row in value_df.iterrows():\n",
    "            source_link_col = [col for col in cols if col == \"Source/Link\"]\n",
    "            alternate_vals = filter(None, row[source_link_col])\n",
    "            alternate_vals=list(alternate_vals)\n",
    "            if alternate_vals and str(alternate_vals[0]).startswith(\"http\"):\n",
    "                url_lists.append(alternate_vals[0])\n",
    "    url_content=[]\n",
    "    urls=[]\n",
    "    count=0\n",
    "    for url in url_lists:\n",
    "        response=requests.get(url)\n",
    "        html_page = response.text\n",
    "        soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "        text=soup.get_text()\n",
    "        text = re.sub(r'[\\t\\n\\r\\f\\v]+', '', text)\n",
    "        text=re.sub(r'[^\\w\\s]', '', text)\n",
    "        url=url.strip()\n",
    "        if url not in used_urls and url not in train_30_urls:\n",
    "            url_content.append(text)\n",
    "            urls.append(url)\n",
    "        used_urls.append(url)\n",
    "\n",
    "\n",
    "    import json\n",
    "    print(len(url_content))\n",
    "    metadata_extractor = InstructorBasedOpenAIMetadataExtractor(\n",
    "    model=\"ft:gpt-3.5-turbo-1106:nasa::8sDqIEsU\",\n",
    "    schema=schema,\n",
    "    preprocessor=text_processor,\n",
    "    debug=True,\n",
    ")\n",
    "\n",
    "    response_result={}\n",
    "    for enum,text in enumerate(url_content):\n",
    "        split=text.split()\n",
    "        if len(split)>1900:\n",
    "            text=\" \".join(split[0:1800])\n",
    "        metadata = metadata_extractor(text)\n",
    "        response=json.loads((metadata['choices'][0]['message'][\"function_call\"][\"arguments\"]))\n",
    "        response_result[urls[enum]]=response\n",
    "        print(enum,len(text.split()))\n",
    "    with open(\"finetuned_extractions/epoch10/gpt3.5_125/\"+each_sheet+\".json\",'w') as file:\n",
    "            json.dump(response_result,file,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e8f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "import re \n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "\n",
    "encoder = SentenceTransformer('all-mpnet-base-v2').to('cpu')\n",
    "\n",
    "# Evaluation Metric: Exact Match  #Indicators\n",
    "def evaluate_exact_match(predicted, ground_truth):\n",
    "    return int(predicted.lower() == ground_truth.lower())\n",
    "\n",
    "# Evaluation Metric: description, project, geographic measure\n",
    "def evaluate_similarity_or_edit_distance(predicted, ground_truth1,ground_truth2,encoder):\n",
    "    if (type(ground_truth1)==float and type(predicted)==float) or (type(ground_truth2)==float and type(predicted)==float):\n",
    "        return 1\n",
    "    elif type(ground_truth1)==float or type(ground_truth2)==float or type(predicted)==float:\n",
    "        return 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        pred_embeddings = encoder.encode(predicted, show_progress_bar=False)\n",
    "        truth1_embeddings = encoder.encode(ground_truth1, show_progress_bar=False)\n",
    "        truth2_embeddings = encoder.encode(ground_truth2, show_progress_bar=False)\n",
    "    similarity1 = cos_sim(pred_embeddings, truth1_embeddings).numpy()[0][0]\n",
    "    similarity2 = cos_sim(pred_embeddings, truth2_embeddings).numpy() [0][0]\n",
    "    similarity=max(similarity1,similarity2)\n",
    "    if similarity>0.7:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def evaluate_project(predicted, ground_truth,encoder):\n",
    "    if type(predicted)==float and type(ground_truth)==float:\n",
    "        return 1\n",
    "    elif type(ground_truth)==float:\n",
    "        return 0\n",
    "    ground_truth=ground_truth.split(\"-\",1)\n",
    "    with torch.no_grad():\n",
    "        pred_embeddings = encoder.encode(predicted, show_progress_bar=False)\n",
    "        truth1_embeddings = encoder.encode(ground_truth[0], show_progress_bar=False)\n",
    "        similarity = cos_sim(pred_embeddings, truth1_embeddings).numpy()[0][0]\n",
    "        if len(ground_truth)>1:\n",
    "            truth2_embeddings = encoder.encode(ground_truth[1], show_progress_bar=False)\n",
    "            similarity1 = cos_sim(pred_embeddings, truth2_embeddings).numpy()[0][0]\n",
    "            similarity=max(similarity,similarity1)\n",
    "    if similarity>0.55:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Evaluation Metric: Exact Match or at least one match if multiple\n",
    "def evaluate_format(predicted, ground_truth):\n",
    "    predicted = np.nan if predicted==\"N/A\" else predicted\n",
    "    if type(predicted)==float and type(ground_truth)==float:\n",
    "        return 1\n",
    "    elif type(predicted)==float or type(ground_truth)==float:\n",
    "        return 0\n",
    "    predicted=predicted.lower()\n",
    "    ground_truth=ground_truth.lower()\n",
    "    if predicted==ground_truth:\n",
    "        return 1\n",
    "    predicted_formats = set(predicted.split(\",\"))\n",
    "    ground_truth_formats = set(ground_truth.split(\",\"))\n",
    "    if predicted_formats.intersection(ground_truth_formats):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def evaluate_spatial_resolution(predicted, ground_truth1,ground_truth2):\n",
    "    predicted = np.nan if predicted==\"N/A\" else predicted\n",
    "    if (type(predicted)==float and type(ground_truth1)==float) or (type(predicted)==float and type(ground_truth2)==float):\n",
    "        return 1\n",
    "    elif (type(ground_truth1)==float or type(ground_truth2)==float):\n",
    "        return 0\n",
    "    elif type(predicted)==float:\n",
    "        return 0\n",
    "    predicted=predicted.lower()\n",
    "    ground_truth1=ground_truth1.lower()\n",
    "    ground_truth2=ground_truth2.lower()\n",
    "    if (\"varies\" in predicted and \"varies\" in ground_truth1) or (\"varies\" in predicted and \"varies\" in ground_truth2):\n",
    "        return 1\n",
    "    if (predicted==ground_truth1) or (predicted==ground_truth2):\n",
    "        return 1\n",
    "    predicted = re.sub(r'[a-zA-Z\\(\\)\\[\\]]', '', predicted).strip()\n",
    "    ground_truth1=re.sub(r'[a-zA-Z\\(\\)\\[\\]]', '', ground_truth1).strip()\n",
    "    ground_truth2=re.sub(r'[a-zA-Z\\(\\)\\[\\]]', '', ground_truth2).strip()\n",
    "    if not (ground_truth1 or ground_truth2) and predicted.find(',') != -1:\n",
    "        return 1\n",
    "    ground_truth1=re.sub(r'[^\\d.]', '', ground_truth1)\n",
    "    ground_truth2=re.sub(r'[^\\d.]', '', ground_truth2)\n",
    "    predicted=re.sub(r'[^\\d.]', '', predicted)\n",
    "    if predicted==ground_truth1 or predicted==ground_truth2:\n",
    "        return 1\n",
    "    if predicted and ((ground_truth1 and (predicted.replace(\" \",\"\")==ground_truth1.replace(\" \",\"\"))) or (ground_truth2 and (predicted.replace(\" \",\"\")==ground_truth2.replace(\" \",\"\")))):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def evaluate_latency(predicted, ground_truth):\n",
    "    predicted = np.nan if predicted==\"N/A\" else predicted\n",
    "    if type(predicted)==float and type(ground_truth)==float:\n",
    "        return 1\n",
    "    if type(predicted)==float or type(ground_truth)==float:\n",
    "        return 0\n",
    "    predicted=predicted.lower()\n",
    "    ground_truth=ground_truth.lower()\n",
    "    if \"varies\" in predicted and \"varies\" in ground_truth:\n",
    "        return 1\n",
    "    if (predicted==ground_truth):\n",
    "        return 1\n",
    "    predicted = re.sub(r'[a-zA-Z]', '', predicted)\n",
    "    predicted=re.sub(r'[^a-zA-Z0-9]','',predicted)\n",
    "    ground_truth=re.sub(r'[a-zA-Z]', '', ground_truth)\n",
    "    ground_truth=re.sub(r'[^a-zA-Z0-9]','',ground_truth)\n",
    "    if not ground_truth and not predicted:\n",
    "        return 1\n",
    "    if not ground_truth or not predicted:\n",
    "        return 0\n",
    "    if (int(predicted)==int(ground_truth)):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def evaluate_temporal_resolution_extent(predicted,ground_truth):\n",
    "    predicted = np.nan if predicted==\"N/A\" else predicted\n",
    "    ground_truth=np.nan if (type(ground_truth)==str and ground_truth.lower()==\"nan\") else ground_truth\n",
    "    if type(predicted)==float and type(ground_truth)==float:\n",
    "        return 1\n",
    "    if type(predicted)==float or type(ground_truth)==float:\n",
    "        return 0\n",
    "    result1 = str(ground_truth) in str(predicted)\n",
    "    result2= str(predicted) in str(ground_truth)\n",
    "    if result1 or result2:\n",
    "        return 1\n",
    "    predicted=predicted.lower()\n",
    "    ground_truth=str(ground_truth).lower()\n",
    "    if \"varies\" in predicted and \"varies\" in ground_truth:\n",
    "        return 1\n",
    "    if predicted==ground_truth:\n",
    "        return 1\n",
    "    predicted = ''.join(re.findall(r'\\w', predicted))\n",
    "    ground_truth=''.join(re.findall(r'\\w', ground_truth))\n",
    "    if predicted==ground_truth:\n",
    "        return 1 \n",
    "    return 0\n",
    "\n",
    "def evaluate_data_visualization_indicators(predicted,ground_truth):\n",
    "    if predicted==ground_truth:\n",
    "        return 1\n",
    "    return 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99718ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "sheet_names=[\"Water Availability - Cleaned\", \"Disasters (Disaster Recovery) -\", \n",
    " \"Food Availability - Cleaned\", \"Human Dimensions - Cleaned\", \"Urban Flooding - Cleaned\",\n",
    " \"Extreme Heat - CIP\",\"Health and Air Quality - CIP\", \"Climate (Climate Change) - CIP\"]\n",
    "\n",
    "import json\n",
    "before_finetuned={}\n",
    "for sheet_name in sheet_names:\n",
    "    with open(f\"extractions/gpt3.5_1106/{sheet_name}.json\",'r') as file:\n",
    "        data=json.load(file)\n",
    "    before_finetuned.update(data)\n",
    "\n",
    "after_finetuned={}   \n",
    "for sheet_name in sheet_names:\n",
    "    with open(f\"finetuned_extractions/epoch10/gpt3.5_125/{sheet_name}.json\",'r') as file:\n",
    "        data=json.load(file)\n",
    "    after_finetuned.update(data)\n",
    "\n",
    "\n",
    "true_data = {}\n",
    "repeated_rows=[]\n",
    "for sheet_name in sheet_names:\n",
    "    mapper = pd.read_excel(\"nasa_esds.xlsx\", sheet_name=[sheet_name])\n",
    "    for field_key, value_df in mapper.items():\n",
    "        cols = value_df.columns\n",
    "        for i, row in value_df.iterrows():\n",
    "            source_link_col = [\"Source/Link\",\"Indicators                     (Select from drop-down list)\",\"Description\",\"Description Simplified\",\"Geographic Coverage\",\"Format\",\"Spatial Resolution\",\"Spatial Resolution (standard)\",\"Temporal Resolution\",\"Temporal Extent\",\"Latency\",\"Project\",\"Data Visualization\"]\n",
    "            alternate_vals=row[source_link_col]\n",
    "            alternate_vals=list(alternate_vals)\n",
    "            source_link_col[1]=\"Indicators\"\n",
    "            alternate_values=alternate_vals[1:]\n",
    "            value={}\n",
    "            for enum,i in enumerate(source_link_col[1:]):\n",
    "                if i==\"Data Visualization\":\n",
    "                    if isinstance(alternate_values[enum],str):\n",
    "                        value[i]=True\n",
    "                    else:\n",
    "                        value[i]=False\n",
    "                else:\n",
    "                    value[i]=alternate_values[enum]\n",
    "            if alternate_vals[0] in true_data.keys():\n",
    "                repeated_rows.append(alternate_vals[0])\n",
    "            if alternate_vals[0] not in [np.nan, 'DBF', 'Facebook Data For Good High Resolution Population Density Maps']:\n",
    "                true_data[alternate_vals[0].strip()]=value\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f25cddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_keys = set(before_finetuned.keys()) & set(after_finetuned.keys()) & set(true_data.keys())\n",
    "before_finetuned={k:before_finetuned[k] for k in intersection_keys}\n",
    "after_finetuned={k:after_finetuned[k] for k in intersection_keys}\n",
    "true_data={k:true_data[k] for k in intersection_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b60876f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37034b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_metrics(true_data,pred_data):\n",
    "    metrics={}\n",
    "    for key in true_data.keys():\n",
    "        reject_key=[np.nan, 'DBF', 'Facebook Data For Good High Resolution Population Density Maps']\n",
    "        if key not in reject_key:\n",
    "            true_source=true_data[key]\n",
    "            try:\n",
    "                pred_source=pred_data[key]\n",
    "            except:\n",
    "                pred_source=pred_data[key.strip()]\n",
    "            for each_key in pred_source.keys():\n",
    "                if each_key==\"Indicators\":\n",
    "                    result=evaluate_exact_match(pred_source[each_key],true_source[each_key])\n",
    "                    if each_key not in metrics.keys():\n",
    "                            metrics[each_key]=[result]\n",
    "                    else:\n",
    "                        metrics[each_key].append(result)\n",
    "                elif each_key==\"Description\":\n",
    "                    result=evaluate_similarity_or_edit_distance(pred_source[each_key], true_source[each_key],true_source[\"Description Simplified\"],encoder)\n",
    "                    if each_key not in metrics.keys():\n",
    "                        metrics[each_key]=[result]\n",
    "                    else:\n",
    "                        metrics[each_key].append(result)\n",
    "                elif each_key==\"Geographic_Coverage\":\n",
    "                    evaluate_format(pred_source[each_key],true_source[\"Geographic Coverage\"])\n",
    "                    if each_key not in metrics.keys():\n",
    "                        metrics[each_key]=[result]\n",
    "                    else:\n",
    "                        metrics[each_key].append(result) \n",
    "                elif each_key==\"Format\":\n",
    "                    result=evaluate_format(pred_source[each_key],true_source[each_key])\n",
    "                    if each_key not in metrics.keys():\n",
    "                        metrics[each_key]=[result]\n",
    "                    else:\n",
    "                        metrics[each_key].append(result)\n",
    "                elif each_key==\"Spatial_Resolution\":\n",
    "                    result=evaluate_spatial_resolution(pred_source[each_key],true_source[\"Spatial Resolution\"],true_source[\"Spatial Resolution (standard)\"])\n",
    "                    if each_key not in metrics.keys():\n",
    "                        metrics[each_key]=[result]\n",
    "                    else:\n",
    "                        metrics[each_key].append(result)\n",
    "                elif each_key==\"Temporal_Resolution\":\n",
    "                    result=evaluate_temporal_resolution_extent(pred_source[each_key],true_source[\"Temporal Resolution\"])\n",
    "                    if each_key not in metrics.keys():\n",
    "                        metrics[each_key]=[result]\n",
    "                    else:\n",
    "                        metrics[each_key].append(result)\n",
    "                elif each_key==\"Temporal_Extent\":\n",
    "                    result=evaluate_temporal_resolution_extent(pred_source[each_key],true_source[\"Temporal Extent\"])\n",
    "                    if each_key not in metrics.keys():\n",
    "                        metrics[each_key]=[result]\n",
    "                    else:\n",
    "                        metrics[each_key].append(result)\n",
    "                elif each_key==\"Latency\":\n",
    "                    result=evaluate_latency(pred_source[each_key],true_source[\"Latency\"])\n",
    "                    if each_key not in metrics.keys():\n",
    "                        metrics[each_key]=[result]\n",
    "                    else:\n",
    "                        metrics[each_key].append(result)\n",
    "                elif each_key==\"Project\":\n",
    "                    result=evaluate_project(pred_source[each_key], true_source[each_key],encoder)\n",
    "                    if each_key not in metrics.keys():\n",
    "                        metrics[each_key]=[result]\n",
    "                    else:\n",
    "                        metrics[each_key].append(result)\n",
    "                elif each_key==\"Data_Visualization\":\n",
    "                    result=evaluate_data_visualization_indicators(pred_source[each_key], true_source[\"Data Visualization\"])\n",
    "                    if each_key not in metrics.keys():\n",
    "                        metrics[each_key]=[result]\n",
    "                    else:\n",
    "                        metrics[each_key].append(result)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "356ff07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def print_metrics(metrics,mode):\n",
    "    print(f\"The metrics {mode} finetuning is:\")\n",
    "    predictions=metrics\n",
    "    aspect_metrics = {}\n",
    "    for aspect, preds in predictions.items():\n",
    "        if aspect==\"Data_Visualization\":\n",
    "            accuracy=accuracy_score(preds)\n",
    "        accuracy = accuracy_score(preds, [1]*len(preds))  # Assuming ground truth is always 1\n",
    "        precision = precision_score(preds, [1]*len(preds))\n",
    "        recall = recall_score(preds, [1]*len(preds))\n",
    "        f1 = f1_score(preds, [1]*len(preds))\n",
    "        aspect_metrics[aspect] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}\n",
    "\n",
    "    # Print metrics\n",
    "    for aspect, metrics_ in aspect_metrics.items():\n",
    "        print(aspect)\n",
    "        for metric, value in metrics_.items():\n",
    "            print(f\"{metric}: {value:.2f}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846fba1",
   "metadata": {},
   "source": [
    "# printed for finetuning on 125 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "572a75de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metrics before finetuning is:\n",
      "Indicators\n",
      "Accuracy: 0.32\n",
      "Precision: 0.32\n",
      "Recall: 1.00\n",
      "F1-score: 0.48\n",
      "\n",
      "\n",
      "Description\n",
      "Accuracy: 0.56\n",
      "Precision: 0.56\n",
      "Recall: 1.00\n",
      "F1-score: 0.72\n",
      "\n",
      "\n",
      "Geographic_Coverage\n",
      "Accuracy: 0.56\n",
      "Precision: 0.56\n",
      "Recall: 1.00\n",
      "F1-score: 0.72\n",
      "\n",
      "\n",
      "Format\n",
      "Accuracy: 0.04\n",
      "Precision: 0.04\n",
      "Recall: 1.00\n",
      "F1-score: 0.08\n",
      "\n",
      "\n",
      "Spatial_Resolution\n",
      "Accuracy: 0.52\n",
      "Precision: 0.52\n",
      "Recall: 1.00\n",
      "F1-score: 0.68\n",
      "\n",
      "\n",
      "Temporal_Resolution\n",
      "Accuracy: 0.44\n",
      "Precision: 0.44\n",
      "Recall: 1.00\n",
      "F1-score: 0.61\n",
      "\n",
      "\n",
      "Temporal_Extent\n",
      "Accuracy: 0.20\n",
      "Precision: 0.20\n",
      "Recall: 1.00\n",
      "F1-score: 0.33\n",
      "\n",
      "\n",
      "Latency\n",
      "Accuracy: 0.56\n",
      "Precision: 0.56\n",
      "Recall: 1.00\n",
      "F1-score: 0.72\n",
      "\n",
      "\n",
      "Project\n",
      "Accuracy: 0.32\n",
      "Precision: 0.32\n",
      "Recall: 1.00\n",
      "F1-score: 0.48\n",
      "\n",
      "\n",
      "Data_Visualization\n",
      "Accuracy: 0.72\n",
      "Precision: 0.72\n",
      "Recall: 1.00\n",
      "F1-score: 0.84\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "before_metrics=boolean_metrics(true_data,before_finetuned)\n",
    "print_metrics(before_metrics,mode=\"before\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c1f10cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metrics after finetuning is:\n",
      "Indicators\n",
      "Accuracy: 0.32\n",
      "Precision: 0.32\n",
      "Recall: 1.00\n",
      "F1-score: 0.48\n",
      "\n",
      "\n",
      "Description\n",
      "Accuracy: 0.56\n",
      "Precision: 0.56\n",
      "Recall: 1.00\n",
      "F1-score: 0.72\n",
      "\n",
      "\n",
      "Geographic_Coverage\n",
      "Accuracy: 0.56\n",
      "Precision: 0.56\n",
      "Recall: 1.00\n",
      "F1-score: 0.72\n",
      "\n",
      "\n",
      "Format\n",
      "Accuracy: 0.04\n",
      "Precision: 0.04\n",
      "Recall: 1.00\n",
      "F1-score: 0.08\n",
      "\n",
      "\n",
      "Spatial_Resolution\n",
      "Accuracy: 0.52\n",
      "Precision: 0.52\n",
      "Recall: 1.00\n",
      "F1-score: 0.68\n",
      "\n",
      "\n",
      "Temporal_Resolution\n",
      "Accuracy: 0.44\n",
      "Precision: 0.44\n",
      "Recall: 1.00\n",
      "F1-score: 0.61\n",
      "\n",
      "\n",
      "Temporal_Extent\n",
      "Accuracy: 0.20\n",
      "Precision: 0.20\n",
      "Recall: 1.00\n",
      "F1-score: 0.33\n",
      "\n",
      "\n",
      "Latency\n",
      "Accuracy: 0.56\n",
      "Precision: 0.56\n",
      "Recall: 1.00\n",
      "F1-score: 0.72\n",
      "\n",
      "\n",
      "Project\n",
      "Accuracy: 0.32\n",
      "Precision: 0.32\n",
      "Recall: 1.00\n",
      "F1-score: 0.48\n",
      "\n",
      "\n",
      "Data_Visualization\n",
      "Accuracy: 0.72\n",
      "Precision: 0.72\n",
      "Recall: 1.00\n",
      "F1-score: 0.84\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "after_metrics=boolean_metrics(true_data,after_finetuned)\n",
    "print_metrics(before_metrics,mode=\"after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10eca5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(before_finetuned))\n",
    "print(len(true_data))\n",
    "print(len(after_finetuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea5419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
