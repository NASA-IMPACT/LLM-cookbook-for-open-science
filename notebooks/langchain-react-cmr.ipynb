{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMR Query ReACT Agent\n",
    "\n",
    "#### Using Langchain Agent Library\n",
    "\n",
    "This Notebook demonstrates how to use the Langchain Agent Library to query the CMR API. It uses the ReACT prompt pattern that language model leverages to chain multiple external tools (e.g. geocoding) together to geenrate a valid CMR query from natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (0.1.13)\n",
      "Requirement already satisfied: opencage in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (2.4.0)\n",
      "Requirement already satisfied: utils in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (1.0.2)\n",
      "Requirement already satisfied: httpx in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (0.27.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (0.0.29)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (0.1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (0.1.23)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: backoff>=2.2.1 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from opencage) (2.2.1)\n",
      "Requirement already satisfied: anyio in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from httpx) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from httpx) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from httpx) (1.0.4)\n",
      "Requirement already satisfied: idna in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from httpx) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from httpx) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx) (0.14.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain opencage utils httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import dotenv\n",
    "import httpx\n",
    "import tiktoken\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.llms import OpenAI, AzureOpenAI\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from typing import List, Union\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleActionAgent,\n",
    ")\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "import pprint\n",
    "pprinter = pprint.PrettyPrinter(indent=4, width=120, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReACT Agent\n",
    "\n",
    "The ReACT agent model refers to a framework that integrates the reasoning capabilities of large language models (LLMs) with the ability to take actionable steps, creating a more sophisticated system that can understand and process information, evaluate situations, take appropriate actions, communicate responses, and track ongoing situations.\n",
    "\n",
    "The main components of the ReACT agent are:\n",
    "- Chain of Thought - ReACT Prompt\n",
    "- Tools for LLMs to use - ReACT Actions\n",
    "- Helper functions to control and route the Agent's actions - ReACT Controllers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#react template\n",
    "cmr_template = \"\"\"\n",
    "You are responsible to provide a CMR Link to the User's Query. \n",
    "Use 'keyword=' to build CMR Query. DO NOT USE 'science_keywords[]='\n",
    "You have access to the following tools to build the CMR Link:\n",
    "Use this Base URL: \"https://cmr.earthdata.nasa.gov/search/collections?\"\n",
    "If the temporal or spatial information is not available, provide the link without it.\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Query: the input question you must answer\n",
    "Thought: you should always think about what to do. If the Query is not a valid CMR query, Provide Final Answer asking the user to provide the correct CMR query. Any other question to the user will need to be given as Final Answer.\n",
    "Action: the action to take, should be one of [{tool_names}].\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times until you have all the information to build the CMR Link)\n",
    "Thought: I now have all the information for CMR query\n",
    "Final Answer: Provide the link. If a link is not available, suggest the user how to modify the query to get the link.\n",
    "\n",
    "Begin Loop:\n",
    "\n",
    "Query: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "\n",
    "datetime_template = \"\"\"\n",
    "            convert time string: {datetime} into start and end datetime formatted as: 'temporal[]=yyyy-MM-ddTHH:mm:ssZ,yyyy-MM-ddTHH:mm:ssZ'\n",
    "            \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "Tools are external functions that can be used by the agent to perform specific tasks. \n",
    "\n",
    "External Tools used By the CMR Agent:\n",
    "\n",
    "- Datetime identifier and formatting\n",
    "- Keyword extraction\n",
    "- geo-location extraction\n",
    "- Bounding Box formatting for geo-location\n",
    "- CMR API formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencage_geocoder = OpenCageGeocode(os.environ[\"OPENCAGE_API_KEY\"])\n",
    "\n",
    "class DatetimeChain(LLMChain):\n",
    "    \"\"\"Find datetime for a given time string or a range of time strings. e.g (between 2010 and 2020)\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        today = datetime.date.today()\n",
    "        today_string = (\n",
    "            f\"Assume the current year and month is {today.year} and {today.month}.\"\n",
    "        )\n",
    "        template = datetime_template.strip() + today_string\n",
    "        prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"datetime\"],\n",
    "        )\n",
    "        super().__init__(prompt=prompt, llm=OpenAI(temperature=0), *args, **kwargs)\n",
    "        super().__init__(prompt=prompt, llm=AzureOpenAI(temperature=0), *args, **kwargs)\n",
    "\n",
    "    def _run(self, timestring: str) -> str:\n",
    "        \"\"\"Find datetime for a given time string\"\"\"\n",
    "        return self.predict(datetime=timestring)\n",
    "\n",
    "    async def _arun(self, timestring: str) -> str:\n",
    "        \"\"\"asynchronous call to find datetime for a given time string\"\"\"\n",
    "        return self.predict(datetime=timestring)\n",
    "\n",
    "\n",
    "class BoundingBoxFinderTool(BaseTool):\n",
    "    name = \"bounding_box_finder\"\n",
    "    description = \"useful to find bounding box in min Longitude, min Latitude, max Longitude, max Latitude format for a given location, region, or a landmark. The output is formatted for CMR API.\"\n",
    "    geocoder = opencage_geocoder\n",
    "\n",
    "    def _run(self, tool_input: str) -> str:\n",
    "        \"\"\"Geocode a query (location, region, landmark)\"\"\"\n",
    "        response = self.geocoder.geocode(tool_input, no_annotations=\"1\")\n",
    "        if response:\n",
    "            bounds = response[0][\"bounds\"]\n",
    "            # convert to bbox\n",
    "            bbox = \"{},{},{},{}\".format(\n",
    "                bounds[\"southwest\"][\"lng\"],\n",
    "                bounds[\"southwest\"][\"lat\"],\n",
    "                bounds[\"northeast\"][\"lng\"],\n",
    "                bounds[\"northeast\"][\"lat\"],\n",
    "            )\n",
    "            return f\"bounding_box[]={bbox}\"\n",
    "        return \"Cannot parse the query\"\n",
    "\n",
    "    async def _arun(self, tool_input: str) -> str:\n",
    "        \"\"\"asynchronous call to Geocode a query\"\"\"\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = self.geocoder.geocode(tool_input, no_annotations=\"1\")\n",
    "            if response:\n",
    "                bounds = response[0][\"bounds\"]\n",
    "                # convert to bbox\n",
    "                # bounding_box[]=\n",
    "                bbox = \"{},{},{},{}\".format(\n",
    "                    bounds[\"southwest\"][\"lng\"],\n",
    "                    bounds[\"southwest\"][\"lat\"],\n",
    "                    bounds[\"northeast\"][\"lng\"],\n",
    "                    bounds[\"northeast\"][\"lat\"],\n",
    "                )\n",
    "                return f\"bounding_box[]={bbox}\"\n",
    "\n",
    "            else:\n",
    "                return \"Cannot parse the query\"\n",
    "\n",
    "\n",
    "def geocode(text: str) -> str:\n",
    "    \"\"\"Geocode a query (location, region, or landmark)\"\"\"\n",
    "    response = opencage_geocoder.geocode(text, no_annotations=\"1\")\n",
    "    if response:\n",
    "        bounds = response[0][\"bounds\"]\n",
    "        # convert to bbox\n",
    "        bbox = \"{},{},{},{}\".format(\n",
    "            bounds[\"southwest\"][\"lng\"],\n",
    "            bounds[\"southwest\"][\"lat\"],\n",
    "            bounds[\"northeast\"][\"lng\"],\n",
    "            bounds[\"northeast\"][\"lat\"],\n",
    "        )\n",
    "        return f\"bounding_box[]={bbox}\"\n",
    "\n",
    "\n",
    "class CMRQueryTool(BaseTool):\n",
    "    name = \"cmr_query_api\"\n",
    "    description = \"useful for Querying CMR API based on previous Observations. input is query parameters string\"\n",
    "    base_url = \"https://cmr.earthdata.nasa.gov/search/collections?\"\n",
    "\n",
    "    def _run(self, tool_input: str) -> str:\n",
    "        k: int = 40\n",
    "        \"\"\"Filter a CMR response\"\"\"\n",
    "\n",
    "        if self.base_url in tool_input:\n",
    "            tool_input = tool_input.replace(self.base_url, \"\")\n",
    "        return self.base_url + tool_input\n",
    "\n",
    "    async def _arun(self, tool_input: str) -> str:\n",
    "        \"\"\"asynchronous call to filter a CMR response\"\"\"\n",
    "        return [self._filter_response(tool_input)]\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain\n",
    "\n",
    "Langchain is a library that provides a set of tools to interact with language models, such as GPT-3, and to build agents that can understand and process information, evaluate situations, take appropriate actions, communicate responses, and track ongoing situations. Below is a simple example of how to use the library to implement a ReACT agent.\n",
    "\n",
    "Components used:\n",
    "CustomPromptTemplate - ReACT Prompt class\n",
    "CustomOutputParser - ReACT Output controller class for routing LLM actions\n",
    "Agent - ReACT Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.azure_openai.AzureChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain.agents.agent.LLMSingleActionAgent` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    \"\"\"\n",
    "    This is a custom prompt template that uses the `cmr_template` from `prompts.py`\n",
    "    \"\"\"\n",
    "\n",
    "    template: str\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in self.tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]\n",
    "\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \"\"\"\n",
    "    This is a custom output parser that parses the output of the LLM agent\n",
    "    \"\"\"\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        \n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )\n",
    "\n",
    "\n",
    "class CMRQueryAgent:\n",
    "    \"\"\"\n",
    "    This is a custom agent that uses the `CustomPromptTemplate` and `CustomOutputParser`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.create_tools()\n",
    "        self.tool_names = [tool.name for tool in self.tools]\n",
    "        self.prompt = CustomPromptTemplate(\n",
    "            template=cmr_template,\n",
    "            tools=self.tools,\n",
    "            # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "            # This includes the `intermediate_steps` variable because that is needed\n",
    "            input_variables=[\"input\", \"intermediate_steps\"],\n",
    "        )\n",
    "        self.output_parser = CustomOutputParser()\n",
    "        # openai.api_type = \"openai\"\n",
    "        # self.llm_chain = LLMChain(\n",
    "        #     llm=ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0),\n",
    "        #     prompt=self.prompt,\n",
    "        # )\n",
    "        self.llm_chain = LLMChain(\n",
    "            llm=AzureChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0),\n",
    "            prompt=self.prompt,\n",
    "        )\n",
    "        self.create_agent()\n",
    "\n",
    "    def create_tools(self):\n",
    "        \"\"\"create tools for the agent\"\"\"\n",
    "        self.tools = [\n",
    "            Tool(\n",
    "                name=BoundingBoxFinderTool().name,\n",
    "                description=BoundingBoxFinderTool().description,\n",
    "                func=BoundingBoxFinderTool().run,\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"DateTime Extractor\",\n",
    "                description=\"Extracts time string and converts it to a datetime format\",\n",
    "                func=DatetimeChain().run,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def create_agent(self):\n",
    "        self.agent = LLMSingleActionAgent(\n",
    "            llm_chain=self.llm_chain,\n",
    "            output_parser=self.output_parser,\n",
    "            stop=[\"\\nObservation:\"],\n",
    "            allowed_tools=self.tool_names,\n",
    "        )\n",
    "        self.agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "            agent=self.agent, tools=self.tools, verbose=True\n",
    "        )\n",
    "\n",
    "    def run_query(self, input_text: str):\n",
    "        return self.agent_executor.run(input_text)\n",
    "\n",
    "query_agent = CMRQueryAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the bounding box for Indonesia and convert the past three years into a datetime range for the CMR query.\n",
      "Action: bounding_box_finder\n",
      "Action Input: Indonesia\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mbounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now have the bounding box for Indonesia. Next, I need to convert \"the past three years\" into a datetime range.\n",
      "Action: DateTime Extractor\n",
      "Action Input: the past three years\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "start = '2021-01-01T00:00:00Z'\n",
      "end = '2024-03-31T23:59:59Z'\n",
      "\n",
      "temporal[] = start + ',' + end\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now have all the information for CMR query\n",
      "Final Answer: https://cmr.earthdata.nasa.gov/search/collections?keyword=high%20resolution%20precipitation&bounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496&temporal[]=2021-01-01T00:00:00Z,2024-03-31T23:59:59Z\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "https://cmr.earthdata.nasa.gov/search/collections?keyword=high%20resolution%20precipitation&bounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496&temporal[]=2021-01-01T00:00:00Z,2024-03-31T23:59:59Z\n"
     ]
    }
   ],
   "source": [
    "query= \"I want high resolution precipitation data for the past three years over Indonesia\"\n",
    "print(\n",
    "    query_agent.run_query(query)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: This is not a valid CMR query. CMR (Collection Metadata Repository) queries are related to Earth science data collections, not general knowledge or definitions.\n",
      "\n",
      "Final Answer: Please provide a specific Earth science data collection query for CMR. For example, you can ask for satellite data related to \"sea surface temperature\" or \"air quality measurements\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Please provide a specific Earth science data collection query for CMR. For example, you can ask for satellite data related to \"sea surface temperature\" or \"air quality measurements\".\n"
     ]
    }
   ],
   "source": [
    "query= \"What is osmosis?\"\n",
    "print(\n",
    "    query_agent.run_query(query)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
