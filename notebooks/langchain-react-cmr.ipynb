{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMR Query ReACT Agent\n",
    "\n",
    "#### Using Langchain Agent Library\n",
    "\n",
    "This Notebook demonstrates how to use the Langchain Agent Library to query the CMR API. It uses the ReACT prompt pattern that language model leverages to chain multiple external tools (e.g. geocoding) together to geenrate a valid CMR query from natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/iksha/miniforge3/lib/python3.9/site-packages (0.1.13)\n",
      "Requirement already satisfied: opencage in /Users/iksha/miniforge3/lib/python3.9/site-packages (2.3.0)\n",
      "Collecting utils\n",
      "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: httpx in /Users/iksha/miniforge3/lib/python3.9/site-packages (0.25.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/iksha/miniforge3/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-openai in /Users/iksha/miniforge3/lib/python3.9/site-packages (0.1.1)\n",
      "Collecting pydantic==1.10.8\n",
      "  Downloading pydantic-1.10.8-cp39-cp39-macosx_11_0_arm64.whl.metadata (146 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.4/146.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from pydantic==1.10.8) (4.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (0.5.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (0.0.29)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (0.1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (0.1.31)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: backoff>=2.2.1 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from opencage) (2.2.1)\n",
      "Requirement already satisfied: certifi in /Users/iksha/miniforge3/lib/python3.9/site-packages (from httpx) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from httpx) (0.18.0)\n",
      "Requirement already satisfied: idna in /Users/iksha/miniforge3/lib/python3.9/site-packages (from httpx) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/iksha/miniforge3/lib/python3.9/site-packages (from httpx) (1.3.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain-openai) (1.14.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from httpcore<0.19.0,>=0.18.0->httpx) (3.7.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from httpcore<0.19.0,>=0.18.0->httpx) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.17)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: exceptiongroup in /Users/iksha/miniforge3/lib/python3.9/site-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx) (1.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/iksha/miniforge3/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Downloading pydantic-1.10.8-cp39-cp39-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: utils\n",
      "  Building wheel for utils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13926 sha256=c42291f0866d1eff3a45754336146de87cae167b0ab61a126d4e02da7b326153\n",
      "  Stored in directory: /Users/iksha/Library/Caches/pip/wheels/4c/a5/a3/ab48e06c936b39960801612ee2767ff53764119f33d3d646e7\n",
      "Successfully built utils\n",
      "\u001b[33mDEPRECATION: celery 5.0.5 has a non-standard dependency specifier pytz>dev. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of celery or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.3 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: utils, pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.13\n",
      "    Uninstalling pydantic-1.10.13:\n",
      "      Successfully uninstalled pydantic-1.10.13\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "primeqa 0.9.2 requires bitarray~=2.3.7, which is not installed.\n",
      "primeqa 0.9.2 requires datasets[apache-beam]~=2.3.2, which is not installed.\n",
      "primeqa 0.9.2 requires faiss-cpu~=1.7.2, which is not installed.\n",
      "primeqa 0.9.2 requires jsonlines~=3.0.0, which is not installed.\n",
      "primeqa 0.9.2 requires ninja~=1.10.2.3, which is not installed.\n",
      "primeqa 0.9.2 requires pyserini~=0.16.0, which is not installed.\n",
      "primeqa 0.9.2 requires scikit-learn~=1.0.2, which is not installed.\n",
      "primeqa 0.9.2 requires signals~=0.0.2, which is not installed.\n",
      "cognito-client 0.0.1 requires pydantic==1.9.1, but you have pydantic 1.10.8 which is incompatible.\n",
      "marvin 1.5.1 requires typer>=0.9.0, but you have typer 0.7.0 which is incompatible.\n",
      "pydantic-settings 2.0.3 requires pydantic>=2.0.1, but you have pydantic 1.10.8 which is incompatible.\n",
      "radiant-mlhub 0.5.5 requires pydantic~=1.9.2, but you have pydantic 1.10.8 which is incompatible.\n",
      "radiant-mlhub 0.5.5 requires pystac~=1.4.0, but you have pystac 1.7.3 which is incompatible.\n",
      "radiant-mlhub 0.5.5 requires requests~=2.27.0, but you have requests 2.31.0 which is incompatible.\n",
      "radiant-mlhub 0.5.5 requires tqdm~=4.64.0, but you have tqdm 4.66.1 which is incompatible.\n",
      "spacy 3.4.1 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.10.8 which is incompatible.\n",
      "spacy 3.4.1 requires typer<0.5.0,>=0.3.0, but you have typer 0.7.0 which is incompatible.\n",
      "primeqa 0.9.2 requires click~=8.0.4, but you have click 8.1.7 which is incompatible.\n",
      "primeqa 0.9.2 requires numpy~=1.21.5, but you have numpy 1.24.3 which is incompatible.\n",
      "primeqa 0.9.2 requires packaging~=21.3, but you have packaging 23.2 which is incompatible.\n",
      "primeqa 0.9.2 requires pandas~=1.3.5, but you have pandas 2.0.2 which is incompatible.\n",
      "primeqa 0.9.2 requires spacy~=3.2.2, but you have spacy 3.4.1 which is incompatible.\n",
      "primeqa 0.9.2 requires torch~=1.11.0, but you have torch 1.12.1 which is incompatible.\n",
      "primeqa 0.9.2 requires tqdm~=4.64.0, but you have tqdm 4.66.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pydantic-1.10.8 utils-1.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain opencage utils httpx python-dotenv langchain-openai pydantic==1.10.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import dotenv\n",
    "import httpx\n",
    "import tiktoken\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools import BaseTool\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from typing import List, Union\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleActionAgent,\n",
    ")\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "import pprint\n",
    "pprinter = pprint.PrettyPrinter(indent=4, width=120, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReACT Agent\n",
    "\n",
    "The ReACT agent model refers to a framework that integrates the reasoning capabilities of large language models (LLMs) with the ability to take actionable steps, creating a more sophisticated system that can understand and process information, evaluate situations, take appropriate actions, communicate responses, and track ongoing situations.\n",
    "\n",
    "The main components of the ReACT agent are:\n",
    "- Chain of Thought - ReACT Prompt\n",
    "- Tools for LLMs to use - ReACT Actions\n",
    "- Helper functions to control and route the Agent's actions - ReACT Controllers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#react template\n",
    "cmr_template = \"\"\"\n",
    "You are responsible to provide a CMR Link to the User's Query. \n",
    "Use 'keyword=' to build CMR Query. DO NOT USE 'science_keywords[]='\n",
    "You have access to the following tools to build the CMR Link:\n",
    "Use this Base URL: \"https://cmr.earthdata.nasa.gov/search/collections?\"\n",
    "If the temporal or spatial information is not available, provide the link without it.\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Query: the input question you must answer\n",
    "Thought: you should always think about what to do. If the Query is not a valid CMR query, Provide Final Answer asking the user to provide the correct CMR query. Any other question to the user will need to be given as Final Answer.\n",
    "Action: the action to take, should be one of [{tool_names}].\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times until you have all the information to build the CMR Link)\n",
    "Thought: I now have all the information for CMR query\n",
    "Final Answer: Provide the link. If a link is not available, suggest the user how to modify the query to get the link.\n",
    "\n",
    "Begin Loop:\n",
    "\n",
    "Query: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "\n",
    "datetime_template = \"\"\"\n",
    "            convert time string: {datetime} into start and end datetime formatted as: 'temporal[]=yyyy-MM-ddTHH:mm:ssZ,yyyy-MM-ddTHH:mm:ssZ'\n",
    "            \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "Tools are external functions that can be used by the agent to perform specific tasks. \n",
    "\n",
    "External Tools used By the CMR Agent:\n",
    "\n",
    "- Datetime identifier and formatting\n",
    "- Keyword extraction\n",
    "- geo-location extraction\n",
    "- Bounding Box formatting for geo-location\n",
    "- CMR API formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OPENCAGE_API_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/iksha/projects/smd-llm-workshop/notebooks/langchain-react-cmr.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/iksha/projects/smd-llm-workshop/notebooks/langchain-react-cmr.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m opencage_geocoder \u001b[39m=\u001b[39m OpenCageGeocode(os\u001b[39m.\u001b[39;49menviron[\u001b[39m\"\u001b[39;49m\u001b[39mOPENCAGE_API_KEY\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/iksha/projects/smd-llm-workshop/notebooks/langchain-react-cmr.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDatetimeChain\u001b[39;00m(LLMChain):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/iksha/projects/smd-llm-workshop/notebooks/langchain-react-cmr.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Find datetime for a given time string or a range of time strings. e.g (between 2010 and 2020)\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodekey(key)]\n\u001b[1;32m    677\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[39m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OPENCAGE_API_KEY'"
     ]
    }
   ],
   "source": [
    "opencage_geocoder = OpenCageGeocode(os.environ[\"OPENCAGE_API_KEY\"])\n",
    "\n",
    "class DatetimeChain(LLMChain):\n",
    "    \"\"\"Find datetime for a given time string or a range of time strings. e.g (between 2010 and 2020)\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        today = datetime.date.today()\n",
    "        today_string = (\n",
    "            f\"Assume the current year and month is {today.year} and {today.month}.\"\n",
    "        )\n",
    "        template = datetime_template.strip() + today_string\n",
    "        prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"datetime\"],\n",
    "        )\n",
    "        # super().__init__(prompt=prompt, llm=OpenAI(temperature=0), *args, **kwargs)\n",
    "        super().__init__(prompt=prompt, llm=AzureChatOpenAI(temperature=0), *args, **kwargs)\n",
    "\n",
    "    def _run(self, timestring: str) -> str:\n",
    "        \"\"\"Find datetime for a given time string\"\"\"\n",
    "        return self.predict(datetime=timestring)\n",
    "\n",
    "    async def _arun(self, timestring: str) -> str:\n",
    "        \"\"\"asynchronous call to find datetime for a given time string\"\"\"\n",
    "        return self.predict(datetime=timestring)\n",
    "\n",
    "\n",
    "class BoundingBoxFinderTool(BaseTool):\n",
    "    name = \"bounding_box_finder\"\n",
    "    description = \"useful to find bounding box in min Longitude, min Latitude, max Longitude, max Latitude format for a given location, region, or a landmark. The output is formatted for CMR API.\"\n",
    "    geocoder = opencage_geocoder\n",
    "\n",
    "    def _run(self, tool_input: str) -> str:\n",
    "        \"\"\"Geocode a query (location, region, landmark)\"\"\"\n",
    "        response = self.geocoder.geocode(tool_input, no_annotations=\"1\")\n",
    "        if response:\n",
    "            bounds = response[0][\"bounds\"]\n",
    "            # convert to bbox\n",
    "            bbox = \"{},{},{},{}\".format(\n",
    "                bounds[\"southwest\"][\"lng\"],\n",
    "                bounds[\"southwest\"][\"lat\"],\n",
    "                bounds[\"northeast\"][\"lng\"],\n",
    "                bounds[\"northeast\"][\"lat\"],\n",
    "            )\n",
    "            return f\"bounding_box[]={bbox}\"\n",
    "        return \"Cannot parse the query\"\n",
    "\n",
    "    async def _arun(self, tool_input: str) -> str:\n",
    "        \"\"\"asynchronous call to Geocode a query\"\"\"\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = self.geocoder.geocode(tool_input, no_annotations=\"1\")\n",
    "            if response:\n",
    "                bounds = response[0][\"bounds\"]\n",
    "                # convert to bbox\n",
    "                # bounding_box[]=\n",
    "                bbox = \"{},{},{},{}\".format(\n",
    "                    bounds[\"southwest\"][\"lng\"],\n",
    "                    bounds[\"southwest\"][\"lat\"],\n",
    "                    bounds[\"northeast\"][\"lng\"],\n",
    "                    bounds[\"northeast\"][\"lat\"],\n",
    "                )\n",
    "                return f\"bounding_box[]={bbox}\"\n",
    "\n",
    "            else:\n",
    "                return \"Cannot parse the query\"\n",
    "\n",
    "\n",
    "def geocode(text: str) -> str:\n",
    "    \"\"\"Geocode a query (location, region, or landmark)\"\"\"\n",
    "    response = opencage_geocoder.geocode(text, no_annotations=\"1\")\n",
    "    if response:\n",
    "        bounds = response[0][\"bounds\"]\n",
    "        # convert to bbox\n",
    "        bbox = \"{},{},{},{}\".format(\n",
    "            bounds[\"southwest\"][\"lng\"],\n",
    "            bounds[\"southwest\"][\"lat\"],\n",
    "            bounds[\"northeast\"][\"lng\"],\n",
    "            bounds[\"northeast\"][\"lat\"],\n",
    "        )\n",
    "        return f\"bounding_box[]={bbox}\"\n",
    "\n",
    "\n",
    "class CMRQueryTool(BaseTool):\n",
    "    name = \"cmr_query_api\"\n",
    "    description = \"useful for Querying CMR API based on previous Observations. input is query parameters string\"\n",
    "    base_url = \"https://cmr.earthdata.nasa.gov/search/collections?\"\n",
    "\n",
    "    def _run(self, tool_input: str) -> str:\n",
    "        k: int = 40\n",
    "        \"\"\"Filter a CMR response\"\"\"\n",
    "\n",
    "        if self.base_url in tool_input:\n",
    "            tool_input = tool_input.replace(self.base_url, \"\")\n",
    "        return self.base_url + tool_input\n",
    "\n",
    "    async def _arun(self, tool_input: str) -> str:\n",
    "        \"\"\"asynchronous call to filter a CMR response\"\"\"\n",
    "        return [self._filter_response(tool_input)]\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain\n",
    "\n",
    "Langchain is a library that provides a set of tools to interact with language models, such as GPT-3, and to build agents that can understand and process information, evaluate situations, take appropriate actions, communicate responses, and track ongoing situations. Below is a simple example of how to use the library to implement a ReACT agent.\n",
    "\n",
    "Components used:\n",
    "CustomPromptTemplate - ReACT Prompt class\n",
    "CustomOutputParser - ReACT Output controller class for routing LLM actions\n",
    "Agent - ReACT Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    \"\"\"\n",
    "    This is a custom prompt template that uses the `cmr_template` from `prompts.py`\n",
    "    \"\"\"\n",
    "\n",
    "    template: str\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in self.tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]\n",
    "\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \"\"\"\n",
    "    This is a custom output parser that parses the output of the LLM agent\n",
    "    \"\"\"\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        \n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )\n",
    "\n",
    "\n",
    "class CMRQueryAgent:\n",
    "    \"\"\"\n",
    "    This is a custom agent that uses the `CustomPromptTemplate` and `CustomOutputParser`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.create_tools()\n",
    "        self.tool_names = [tool.name for tool in self.tools]\n",
    "        self.prompt = CustomPromptTemplate(\n",
    "            template=cmr_template,\n",
    "            tools=self.tools,\n",
    "            # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "            # This includes the `intermediate_steps` variable because that is needed\n",
    "            input_variables=[\"input\", \"intermediate_steps\"],\n",
    "        )\n",
    "        self.output_parser = CustomOutputParser()\n",
    "        # openai.api_type = \"openai\"\n",
    "        # self.llm_chain = LLMChain(\n",
    "        #     llm=ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0),\n",
    "        #     prompt=self.prompt,\n",
    "        # )\n",
    "        self.llm_chain = LLMChain(\n",
    "            llm=AzureChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0),\n",
    "            prompt=self.prompt,\n",
    "        )\n",
    "        self.create_agent()\n",
    "\n",
    "    def create_tools(self):\n",
    "        \"\"\"create tools for the agent\"\"\"\n",
    "        self.tools = [\n",
    "            Tool(\n",
    "                name=BoundingBoxFinderTool().name,\n",
    "                description=BoundingBoxFinderTool().description,\n",
    "                func=BoundingBoxFinderTool().run,\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"DateTime Extractor\",\n",
    "                description=\"Extracts time string and converts it to a datetime format\",\n",
    "                func=DatetimeChain().run,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def create_agent(self):\n",
    "        self.agent = LLMSingleActionAgent(\n",
    "            llm_chain=self.llm_chain,\n",
    "            output_parser=self.output_parser,\n",
    "            stop=[\"\\nObservation:\"],\n",
    "            allowed_tools=self.tool_names,\n",
    "        )\n",
    "        self.agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "            agent=self.agent, tools=self.tools, verbose=True\n",
    "        )\n",
    "\n",
    "    def run_query(self, input_text: str):\n",
    "        return self.agent_executor.run(input_text)\n",
    "\n",
    "query_agent = CMRQueryAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the bounding box for Indonesia and convert the past three years into a datetime range for the CMR query.\n",
      "Action: bounding_box_finder\n",
      "Action Input: Indonesia\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mbounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now have the bounding box for Indonesia. Next, I need to convert \"the past three years\" into a datetime range.\n",
      "Action: DateTime Extractor\n",
      "Action Input: the past three years\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3mGiven the current year and month as March 2024, and the request to convert \"the past three years\" into a start and end datetime format, we first identify the exact dates.\n",
      "\n",
      "- End date: Since we're considering \"the past three years\" up to March 2024, the end date would be the last moment of February 2024, to include the full span of three years back from March 2024.\n",
      "- Start date: To cover the past three years, we go back to March 2021.\n",
      "\n",
      "Therefore:\n",
      "- Start date: March 1, 2021, at 00:00:00\n",
      "- End date: February 28, 2024, at 23:59:59 (2024 is a leap year, but February is the month before March, so we consider the end of February as the endpoint)\n",
      "\n",
      "Formatted as requested:\n",
      "`temporal[]=2021-03-01T00:00:00Z,2024-02-28T23:59:59Z`\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now have all the information for the CMR query.\n",
      "Final Answer: Here is your CMR link for high resolution precipitation data over Indonesia for the past three years: \"https://cmr.earthdata.nasa.gov/search/collections?bounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496&temporal[]=2021-03-01T00:00:00Z,2024-02-28T23:59:59Z\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Here is your CMR link for high resolution precipitation data over Indonesia for the past three years: \"https://cmr.earthdata.nasa.gov/search/collections?bounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496&temporal[]=2021-03-01T00:00:00Z,2024-02-28T23:59:59Z\"\n"
     ]
    }
   ],
   "source": [
    "query= \"I want high resolution precipitation data for the past three years over Indonesia\"\n",
    "print(\n",
    "    query_agent.run_query(query)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: This is not a valid CMR query. CMR (Collection Metadata Repository) queries are related to Earth science data collections, not general knowledge or definitions.\n",
      "\n",
      "Final Answer: Please provide a specific Earth science data collection query for CMR. For example, you can ask for satellite data related to \"sea surface temperature\" or \"air quality measurements\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Please provide a specific Earth science data collection query for CMR. For example, you can ask for satellite data related to \"sea surface temperature\" or \"air quality measurements\".\n"
     ]
    }
   ],
   "source": [
    "query= \"What is osmosis?\"\n",
    "print(\n",
    "    query_agent.run_query(query)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployed Apps\n",
    "\n",
    "Interaction with Deployed version of the chain in AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Here is the CMR link for high-resolution precipitation data for the past three years over Indonesia:\\n\\n[https://cmr.earthdata.nasa.gov/search/collections?bounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496&temporal[]=2021-01-01T00:00:00Z,2024-03-31T23:59:59Z&keyword=precipitation](https://cmr.earthdata.nasa.gov/search/collections?bounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496&temporal[]=2021-01-01T00:00:00Z,2024-03-31T23:59:59Z&keyword=precipitation)\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "query = \"I want high resolution precipitation data for the past three years over Indonesia\"\n",
    "url = \"https://xp775tpyna5dvvsn4q3jkl5fju0hsiup.lambda-url.us-west-2.on.aws/?query=\"\n",
    "\n",
    "response = requests.get(f\"{url}{query}\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8987afb44532b2110e1a5e1b229dd281f8440b44477d285826a54acdd52d8797"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
