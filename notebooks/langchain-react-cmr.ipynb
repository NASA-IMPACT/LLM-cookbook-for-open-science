{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMR Query ReACT Agent\n",
    "\n",
    "#### Using Langchain Agent Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain, opencage, utils, httpx\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "import pprint\n",
    "pprinter = pprint.PrettyPrinter(indent=4, width=120, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReACT Agent\n",
    "\n",
    "The ReACT agent model refers to a framework that integrates the reasoning capabilities of large language models (LLMs) with the ability to take actionable steps, creating a more sophisticated system that can understand and process information, evaluate situations, take appropriate actions, communicate responses, and track ongoing situations.\n",
    "\n",
    "The main components of the ReACT agent are:\n",
    "- Chain of Thought - ReACT Prompt\n",
    "- Tools for LLMs to use - ReACT Actions\n",
    "- Helper functions to control and route the Agent's actions - ReACT Controllers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#react template\n",
    "cmr_template = \"\"\"\n",
    "You are responsible to provide a CMR Link to the User's Query. \n",
    "Use 'keyword=' to build CMR Query. DO NOT USE 'science_keywords[]='\n",
    "You have access to the following tools to build the CMR Link:\n",
    "Use this Base URL: \"https://cmr.earthdata.nasa.gov/search/collections?\"\n",
    "If the temporal or spatial information is not available, provide the link without it.\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Query: the input question you must answer\n",
    "Thought: you should always think about what to do. If the Query is not a valid CMR query, Provide Final Answer asking the user to provide the correct CMR query. Any other question to the user will need to be given as Final Answer.\n",
    "Action: the action to take, should be one of [{tool_names}].\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times until you have all the information to build the CMR Link)\n",
    "Thought: I now have all the information for CMR query\n",
    "Final Answer: Provide the link. If a link is not available, suggest the user how to modify the query to get the link.\n",
    "\n",
    "Begin Loop:\n",
    "\n",
    "Query: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "\n",
    "datetime_template = \"\"\"\n",
    "            convert time string: {datetime} into start and end datetime formatted as: 'temporal[]=yyyy-MM-ddTHH:mm:ssZ,yyyy-MM-ddTHH:mm:ssZ'\n",
    "            \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "External Tools used:\n",
    "\n",
    "- Datetime identifier and formatting\n",
    "- Keyword extraction\n",
    "- geo-location extraction\n",
    "- Bounding Box formatting for geo-location\n",
    "- CMR API formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import dotenv\n",
    "import httpx\n",
    "import tiktoken\n",
    "from langchain.agents import Tool, tool\n",
    "from langchain.tools import BaseTool\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import openai\n",
    "import utils\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "import datetime\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "opencage_geocoder = OpenCageGeocode(os.environ[\"OPENCAGE_API_KEY\"])\n",
    "\n",
    "class DatetimeChain(LLMChain):\n",
    "    \"\"\"Find datetime for a given time string or a range of time strings. e.g (between 2010 and 2020)\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        today = datetime.date.today()\n",
    "        today_string = (\n",
    "            f\"Assume the current year and month is {today.year} and {today.month}.\"\n",
    "        )\n",
    "        template = datetime_template.strip() + today_string\n",
    "        prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"datetime\"],\n",
    "        )\n",
    "        super().__init__(prompt=prompt, llm=OpenAI(temperature=0), *args, **kwargs)\n",
    "\n",
    "    def _run(self, timestring: str) -> str:\n",
    "        \"\"\"Find datetime for a given time string\"\"\"\n",
    "        return self.predict(datetime=timestring)\n",
    "\n",
    "    async def _arun(self, timestring: str) -> str:\n",
    "        \"\"\"asynchronous call to find datetime for a given time string\"\"\"\n",
    "        return self.predict(datetime=timestring)\n",
    "\n",
    "\n",
    "class KeywordChain(LLMChain):\n",
    "    \"\"\"Find science keyword to search CMR in a given input\"\"\"\n",
    "    description = \"useful for extracting text science keywords from the user query\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \n",
    "        prompt = f\"\"\"You are a NASA CMR keyword extractor bot, your task is to extract the science keywords from the following user query: {query}. \n",
    "        Provide ONLY the earth science keywords such as phenomena and observables as the output. Do not provide dates and locations. Do not provide generic keywords such as 'data' and 'information'.\"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            template=prompt,\n",
    "            input_variables=[\"query\"],\n",
    "        )\n",
    "        super().__init__(prompt=prompt, llm=ChatOpenAI(model=\"gpt-4-0613\", temperature=0), *args, **kwargs)\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        return self.predict(query=query)\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "\n",
    "        return self.predict(query=query)\n",
    "\n",
    "class CMRLinkCheckChain(LLMChain):\n",
    "    \"\"\"Check the correctness of a CMR link - and provide a correct link\"\"\"\n",
    "    description = \"useful for checking the correctness of a CMR link - and provide a correct link\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \n",
    "        prompt = f\"You are a CMR link checker bot, your task is to check the correctness of the following CMR Link: {link}. Finally, provide the correct CMR link if the provided link is not correct. if the link is correct, provide the link as the final answer.\"\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            template=prompt,\n",
    "            query_variables=[\"link\"],\n",
    "        )\n",
    "        super().__init__(prompt=prompt, llm=OpenAI(temperature=0), *args, **kwargs)\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Find datetime for a given time string\"\"\"\n",
    "        return self.predict(link=query)\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"asynchronous call to find datetime for a given time string\"\"\"\n",
    "        return self.predict(link=query)\n",
    "\n",
    "class GPTEmbedder:\n",
    "    \"\"\"Embedder for keywords using GPT-3 embeddings\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_file=\"/Users/mramasub/work/cmr-prompt-chain/data/keyword_embeddings.npy\",\n",
    "    ):\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.embedder = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "        self.text_to_add = \"Hierarchy Path: \"\n",
    "        # print pwd\n",
    "        keywords_file = \"../data/keywords.json\"\n",
    "        if os.path.exists(keywords_file):\n",
    "            self.kws = self.read_kws(keywords_file)\n",
    "        else:\n",
    "            # exit\n",
    "            pass\n",
    "        self.model = \"text-embedding-ada-002\"\n",
    "        self.embeddings = (\n",
    "            self.load_from_pkl(embeddings_file)\n",
    "            if os.path.exists(embeddings_file)\n",
    "            else self.create_embeddings()\n",
    "        )\n",
    "\n",
    "        assert len(self.kws) == len(self.embeddings)\n",
    "\n",
    "    def create_embeddings(self):\n",
    "        \"\"\"Create embeddings for all keywords\"\"\"\n",
    "        kws_to_embed = self.kws\n",
    "        embeddings = self._embed_langchain(kws_to_embed)\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def _embed_langchain(self, texts, use_text_to_add=True):\n",
    "        text_to_add = \"\"\n",
    "        if use_text_to_add:\n",
    "            text_to_add = self.text_to_add\n",
    "        return self.embedder.embed_documents([text_to_add + text for text in texts])\n",
    "\n",
    "    def _embed(self, texts, use_text_to_add=True):\n",
    "        text_to_add = \"\"\n",
    "        if use_text_to_add:\n",
    "            text_to_add = self.text_to_add\n",
    "        return openai.Embedding.create(\n",
    "            input=[text_to_add + kw for kw in texts], model=self.model\n",
    "        )\n",
    "\n",
    "    def find_nearest_kw(self, keyword, top_n=1):\n",
    "        \"\"\"Find the nearest keyword to the given keyword\"\"\"\n",
    "        embedding = self._embed_langchain([keyword], use_text_to_add=False)\n",
    "        embedding = np.array(embedding)\n",
    "        distances = np.linalg.norm(self.embeddings - embedding, axis=1)\n",
    "\n",
    "        return [self.kws[i] for i in np.argsort(distances)[:top_n]]\n",
    "\n",
    "    def read_kws(\n",
    "        self,\n",
    "        file,\n",
    "    ):\n",
    "        \"\"\"Read keywords from file\"\"\"\n",
    "        kws = []\n",
    "\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            kws = json.load(f)\n",
    "        return [kw[\"keyword_string\"] for kw in kws]\n",
    "\n",
    "    def load_from_pkl(self, file):\n",
    "        \"\"\"Load embeddings from pickle file\"\"\"\n",
    "        return np.load(file)\n",
    "\n",
    "class BoundingBoxFinderTool(BaseTool):\n",
    "    name = \"bounding_box_finder\"\n",
    "    description = \"useful to find bounding box in min Longitude, min Latitude, max Longitude, max Latitude format for a given location, region, or a landmark. The output is formatted for CMR API.\"\n",
    "    geocoder = opencage_geocoder\n",
    "\n",
    "    def _run(self, tool_input: str) -> str:\n",
    "        \"\"\"Geocode a query (location, region, landmark)\"\"\"\n",
    "        response = self.geocoder.geocode(tool_input, no_annotations=\"1\")\n",
    "        if response:\n",
    "            bounds = response[0][\"bounds\"]\n",
    "            # convert to bbox\n",
    "            bbox = \"{},{},{},{}\".format(\n",
    "                bounds[\"southwest\"][\"lng\"],\n",
    "                bounds[\"southwest\"][\"lat\"],\n",
    "                bounds[\"northeast\"][\"lng\"],\n",
    "                bounds[\"northeast\"][\"lat\"],\n",
    "            )\n",
    "            return f\"bounding_box[]={bbox}\"\n",
    "        return \"Cannot parse the query\"\n",
    "\n",
    "    async def _arun(self, tool_input: str) -> str:\n",
    "        \"\"\"asynchronous call to Geocode a query\"\"\"\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = self.geocoder.geocode(tool_input, no_annotations=\"1\")\n",
    "            if response:\n",
    "                bounds = response[0][\"bounds\"]\n",
    "                # convert to bbox\n",
    "                # bounding_box[]=\n",
    "                bbox = \"{},{},{},{}\".format(\n",
    "                    bounds[\"southwest\"][\"lng\"],\n",
    "                    bounds[\"southwest\"][\"lat\"],\n",
    "                    bounds[\"northeast\"][\"lng\"],\n",
    "                    bounds[\"northeast\"][\"lat\"],\n",
    "                )\n",
    "                return f\"bounding_box[]={bbox}\"\n",
    "\n",
    "            else:\n",
    "                return \"Cannot parse the query\"\n",
    "\n",
    "\n",
    "def geocode(text: str) -> str:\n",
    "    \"\"\"Geocode a query (location, region, or landmark)\"\"\"\n",
    "    response = opencage_geocoder.geocode(text, no_annotations=\"1\")\n",
    "    if response:\n",
    "        bounds = response[0][\"bounds\"]\n",
    "        # convert to bbox\n",
    "        bbox = \"{},{},{},{}\".format(\n",
    "            bounds[\"southwest\"][\"lng\"],\n",
    "            bounds[\"southwest\"][\"lat\"],\n",
    "            bounds[\"northeast\"][\"lng\"],\n",
    "            bounds[\"northeast\"][\"lat\"],\n",
    "        )\n",
    "        return f\"bounding_box[]={bbox}\"\n",
    "\n",
    "    @tool\n",
    "    async def calculate(expression):\n",
    "        \"\"\"Calculate an expression\"\"\"\n",
    "        return eval(expression)\n",
    "\n",
    "\n",
    "class CMRQueryTool(BaseTool):\n",
    "    name = \"cmr_query_api\"\n",
    "    description = \"useful for Querying CMR API based on previous Observations. input is query parameters string\"\n",
    "    base_url = \"https://cmr.earthdata.nasa.gov/search/collections?\"\n",
    "\n",
    "    def _run(self, tool_input: str) -> str:\n",
    "        k: int = 40\n",
    "        \"\"\"Filter a CMR response\"\"\"\n",
    "\n",
    "        if self.base_url in tool_input:\n",
    "            tool_input = tool_input.replace(self.base_url, \"\")\n",
    "        return self.base_url + tool_input\n",
    "\n",
    "    async def _arun(self, tool_input: str) -> str:\n",
    "        \"\"\"asynchronous call to filter a CMR response\"\"\"\n",
    "        return [self._filter_response(tool_input)]\n",
    "\n",
    "# gpt_embedder = GPTEmbedder(embeddings_file=\"../data/keyword_embeddings.npy\")\n",
    "\n",
    "# class GCMDKeywordSearchTool(BaseTool):\n",
    "#     \"\"\"Search for science keyword in GCMD science keyword database. only earth science keywords are allowed, no other keywords are allowed\"\"\"\n",
    "#     name = \"gcmd_keyword_search\"\n",
    "#     description = \"useful to search for earth science keyword in GCMD database. only earth science keywords and phenomena are allowed as inputs, no other keywords are allowed. The output is formatted for CMR API.\"\n",
    "\n",
    "#     def _run(self, tool_input: str) -> str:\n",
    "#         \"\"\"Search for a keyword in GCMD\"\"\"\n",
    "    \n",
    "#         return self.get_formatted_science_kws(tool_input)\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def get_formatted_science_kws(tool_input: str, top_n=5) -> str:\n",
    "#         \"\"\"Search for a keyword in GCMD\"\"\"\n",
    "#         keywords = [\n",
    "#             GCMDKeywordSearchTool().cmr_science_keyword(kw, keyword_pos)\n",
    "#             for keyword_pos, kw in enumerate(\n",
    "#                 gpt_embedder.find_nearest_kw(tool_input, top_n=top_n)\n",
    "#             )\n",
    "#         ]\n",
    "#         if isinstance(keywords, list):\n",
    "#             return keywords[0]\n",
    "#         return keywords\n",
    "\n",
    "    @staticmethod\n",
    "    def get_science_kws(tool_input: str, top_n=5) -> str:\n",
    "        \"\"\"Search for a keyword in GCMD\"\"\"\n",
    "        return [kw for kw in gpt_embedder.find_nearest_kw(tool_input, top_n=top_n)]\n",
    "\n",
    "    async def _arun(self, tool_input: str) -> str:\n",
    "        \"\"\"Search for a keyword in GCMD\"\"\"\n",
    "        return self.get_formatted_science_kws(tool_input)\n",
    "\n",
    "    @staticmethod\n",
    "    def cmr_science_keyword(keyword_string, keyword_pos):\n",
    "        level_list = [\n",
    "            \"category\",\n",
    "            \"topic\",\n",
    "            \"term\",\n",
    "            \"variable-level-1\",\n",
    "            \"variable-level-2\",\n",
    "            \"variable-level-3\",\n",
    "            \"detailed-variable\",\n",
    "        ]\n",
    "        keyword_list = [key.strip() for key in keyword_string.split(\">\")]\n",
    "\n",
    "        return \"&\".join(\n",
    "            [\n",
    "                rf\"science_keywords[{keyword_pos}][{level_list[i]}]={keyword_list[i].replace(' ', '%20')}\"\n",
    "                for i in range(len(keyword_list))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nstart = '2014-04-01T00:00:00Z'\\nend = '2024-03-31T23:59:59Z'\\n\\ntemporal[] = '2014-04-01T00:00:00Z,2024-03-31T23:59:59Z'\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ext = KeywordChain()\n",
    "# ext.predict(query=\"I want to find the data for the temperature of the earth\")\n",
    "\n",
    "date_time = DatetimeChain()\n",
    "date_time.predict(datetime=\"last 10 years\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain\n",
    "\n",
    "Langchain is a library that provides a set of tools to interact with language models, such as GPT-3, and to build agents that can understand and process information, evaluate situations, take appropriate actions, communicate responses, and track ongoing situations. Below is a simple example of how to use the library to implement a ReACT agent.\n",
    "\n",
    "Components used:\n",
    "CustomPromptTemplate - ReACT Prompt class\n",
    "CustomOutputParser - ReACT Output controller class for routing LLM actions\n",
    "Agent - ReACT Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain.agents.agent.LLMSingleActionAgent` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Union\n",
    "\n",
    "from langchain import LLMChain, OpenAI\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleActionAgent,\n",
    "    Tool,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    \"\"\"\n",
    "    This is a custom prompt template that uses the `cmr_template` from `prompts.py`\n",
    "    \"\"\"\n",
    "\n",
    "    template: str\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in self.tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]\n",
    "\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \"\"\"\n",
    "    This is a custom output parser that parses the output of the LLM agent\n",
    "    \"\"\"\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        \n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )\n",
    "\n",
    "\n",
    "class CMRQueryAgent:\n",
    "    \"\"\"\n",
    "    This is a custom agent that uses the `CustomPromptTemplate` and `CustomOutputParser`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.create_tools()\n",
    "        self.tool_names = [tool.name for tool in self.tools]\n",
    "        self.prompt = CustomPromptTemplate(\n",
    "            template=cmr_template,\n",
    "            tools=self.tools,\n",
    "            # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "            # This includes the `intermediate_steps` variable because that is needed\n",
    "            input_variables=[\"input\", \"intermediate_steps\"],\n",
    "        )\n",
    "        self.output_parser = CustomOutputParser()\n",
    "        self.llm_chain = LLMChain(\n",
    "            llm=ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0),\n",
    "            prompt=self.prompt,\n",
    "        )\n",
    "        self.create_agent()\n",
    "\n",
    "    def create_tools(self):\n",
    "        \"\"\"create tools for the agent\"\"\"\n",
    "        self.tools = [\n",
    "            Tool(\n",
    "                name=BoundingBoxFinderTool().name,\n",
    "                description=BoundingBoxFinderTool().description,\n",
    "                func=BoundingBoxFinderTool().run,\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"DateTime Extractor\",\n",
    "                description=\"Extracts time string and converts it to a datetime format\",\n",
    "                func=DatetimeChain().run,\n",
    "            ),\n",
    "            # Tool(\n",
    "            #     name=\"Keyword Extractor\",\n",
    "            #     description=\"Find science keyword to search CMR in a given input\",\n",
    "            #     func=KeywordChain().run,\n",
    "            # ),\n",
    "            # Tool(\n",
    "            #     name=\"Link Checker\",\n",
    "            #     description=CMRLinkCheckChain().description,\n",
    "            #     func=CMRLinkCheckChain().run,\n",
    "            # ),\n",
    "            # Tool(\n",
    "            #     name=GCMDKeywordSearchTool().name,\n",
    "            #     description=GCMDKeywordSearchTool().description,\n",
    "            #     func=GCMDKeywordSearchTool().run,\n",
    "            # ),\n",
    "            # Tool(\n",
    "            #     description=CMRQueryTool().description,\n",
    "            #     func=CMRQueryTool().run,\n",
    "            # ),\n",
    "        ]\n",
    "\n",
    "    def create_agent(self):\n",
    "        self.agent = LLMSingleActionAgent(\n",
    "            llm_chain=self.llm_chain,\n",
    "            output_parser=self.output_parser,\n",
    "            stop=[\"\\nObservation:\"],\n",
    "            allowed_tools=self.tool_names,\n",
    "        )\n",
    "        self.agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "            agent=self.agent, tools=self.tools, verbose=True\n",
    "        )\n",
    "\n",
    "    def run_query(self, input_text: str):\n",
    "        return self.agent_executor.run(input_text)\n",
    "\n",
    "query_agent = CMRQueryAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user is asking for high-resolution precipitation data over Indonesia for the past three years. I need to find the bounding box for Indonesia and the date range for the past three years.\n",
      "\n",
      "Action: bounding_box_finder\n",
      "Action Input: Indonesia\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mbounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI have the bounding box for Indonesia. Now I need to determine the date range for the past three years from the current year, which is 2023.\n",
      "\n",
      "Action: DateTime Extractor\n",
      "Action Input: three years ago from 2023\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Start datetime: 2020-01-01T00:00:00Z\n",
      "End datetime: 2020-12-31T23:59:59Z\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe date range provided is only for the year 2020, which does not cover the past three years. I need to adjust the date range to include 2020, 2021, and 2022.\n",
      "\n",
      "Action: DateTime Extractor\n",
      "Action Input: three years ago from 2023\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Start datetime: 2020-01-01T00:00:00Z\n",
      "End datetime: 2020-12-31T23:59:59Z\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe DateTime Extractor has provided the same date range as before, which only covers the year 2020. However, I need the date range to start from January 1, 2020, and end on December 31, 2022, to cover the past three years.\n",
      "\n",
      "Thought: I now have all the information for the CMR query.\n",
      "\n",
      "Final Answer: To access high-resolution precipitation data for the past three years over Indonesia, use the following CMR link:\n",
      "\n",
      "https://cmr.earthdata.nasa.gov/search/collections?bounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496&temporal=2020-01-01T00:00:00Z,2022-12-31T23:59:59Z&keyword=precipitation\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "To access high-resolution precipitation data for the past three years over Indonesia, use the following CMR link:\n",
      "\n",
      "https://cmr.earthdata.nasa.gov/search/collections?bounding_box[]=94.7717124,-11.2085669,141.0194444,6.2744496&temporal=2020-01-01T00:00:00Z,2022-12-31T23:59:59Z&keyword=precipitation\n"
     ]
    }
   ],
   "source": [
    "query= \"I want high resolution precipitation data for the past three years over Indonesia\"\n",
    "print(\n",
    "    query_agent.run_query(query)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The query \"What is osmosis?\" is not a valid CMR query. It is a general question about a scientific concept, not related to the Earth data or satellite collections that the CMR would index. The user needs to provide a query that can be used to search the CMR database, such as a request for satellite data about a specific region, time period, or environmental parameter.\n",
      "\n",
      "Final Answer: The query \"What is osmosis?\" does not correspond to a CMR search query. If you are looking for satellite data or environmental research related to osmosis or any other topic, please provide specific details such as the location, time frame, or the type of data you are interested in. For example, you could ask for satellite data on water salinity levels in a particular ocean region during a specific time period.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The query \"What is osmosis?\" does not correspond to a CMR search query. If you are looking for satellite data or environmental research related to osmosis or any other topic, please provide specific details such as the location, time frame, or the type of data you are interested in. For example, you could ask for satellite data on water salinity levels in a particular ocean region during a specific time period.\n"
     ]
    }
   ],
   "source": [
    "query= \"What is osmosis?\"\n",
    "print(\n",
    "    query_agent.run_query(query)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
