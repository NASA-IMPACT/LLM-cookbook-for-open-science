{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMR Query ReACT Agent\n",
    "\n",
    "#### Using Langchain Agent Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain, opencage, utils, httpx\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "import pprint\n",
    "pprinter = pprint.PrettyPrinter(indent=4, width=120, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReACT Agent\n",
    "\n",
    "The ReACT agent model refers to a framework that integrates the reasoning capabilities of large language models (LLMs) with the ability to take actionable steps, creating a more sophisticated system that can understand and process information, evaluate situations, take appropriate actions, communicate responses, and track ongoing situations.\n",
    "\n",
    "The main components of the ReACT agent are:\n",
    "- Chain of Thought - ReACT Prompt\n",
    "- Tools for LLMs to use - ReACT Actions\n",
    "- Helper functions to control and route the Agent's actions - ReACT Controllers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#react template\n",
    "cmr_template = \"\"\"\n",
    "Decode the following query as best you can.\n",
    "The query will involve extracting datetime, bounding box and GCMD science keyword. \n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Query: the input question you must answer\n",
    "Thought: you should always think about what to do. If the Query is not a valid CMR query, Provide Final Answer asking the user to provide the correct CMR query. Any other question to the user will need to be given as Final Answer.\n",
    "Action: the action to take, should be one of [{tool_names}].\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now have all the information for CMR query\n",
    "Action: cmr_query_api\n",
    "Action Input: the input to cmr_query_api (This is your last action, do not add any more actions, DO NOT include Base URL)\n",
    "Observation: the result of the action\n",
    "Final Answer: Provide the link from cmr_query_api. If a link is not available, suggest the user how to modify the query to get the link.\n",
    "\n",
    "Begin Loop:\n",
    "\n",
    "Query: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "\n",
    "datetime_template = \"\"\"\n",
    "            convert time string: {datetime} into start and end datetime formatted as: 'temporal[]=yyyy-MM-ddTHH:mm:ssZ,yyyy-MM-ddTHH:mm:ssZ'\n",
    "            \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "External Tools used:\n",
    "\n",
    "- Datetime identifier and formatting\n",
    "- Keyword extraction\n",
    "- geo-location extraction\n",
    "- Bounding Box formatting for geo-location\n",
    "- CMR API formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramasub/work/workshop-usecases-llm/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import dotenv\n",
    "import httpx\n",
    "import tiktoken\n",
    "from langchain.agents import Tool, tool\n",
    "from langchain.tools import BaseTool\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import openai\n",
    "import utils\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "import datetime\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "opencage_geocoder = OpenCageGeocode(os.environ[\"OPENCAGE_API_KEY\"])\n",
    "\n",
    "class DatetimeChain(LLMChain):\n",
    "    \"\"\"Find datetime for a given time string\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        today = datetime.date.today()\n",
    "        today_string = (\n",
    "            f\"Assume the current year and month is {today.year} and {today.month}.\"\n",
    "        )\n",
    "        template = datetime_template.strip() + today_string\n",
    "        prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"datetime\"],\n",
    "        )\n",
    "        super().__init__(prompt=prompt, llm=OpenAI(temperature=0), *args, **kwargs)\n",
    "\n",
    "    def _run(self, timestring: str) -> str:\n",
    "        \"\"\"Find datetime for a given time string\"\"\"\n",
    "        return self.predict(datetime=timestring)\n",
    "\n",
    "    async def _arun(self, timestring: str) -> str:\n",
    "        \"\"\"asynchronous call to find datetime for a given time string\"\"\"\n",
    "        return self.predict(datetime=timestring)\n",
    "\n",
    "\n",
    "class GPTEmbedder:\n",
    "    \"\"\"Embedder for keywords using GPT-3 embeddings\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings_file=\"/Users/mramasub/work/cmr-prompt-chain/data/keyword_embeddings.npy\",\n",
    "    ):\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.embedder = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "        self.text_to_add = \"Hierarchy Path: \"\n",
    "        # print pwd\n",
    "        keywords_file = \"../data/keywords.json\"\n",
    "        if os.path.exists(keywords_file):\n",
    "            self.kws = self.read_kws(keywords_file)\n",
    "        else:\n",
    "            # exit\n",
    "            pass\n",
    "        self.model = \"text-embedding-ada-002\"\n",
    "        self.embeddings = (\n",
    "            self.load_from_pkl(embeddings_file)\n",
    "            if os.path.exists(embeddings_file)\n",
    "            else self.create_embeddings()\n",
    "        )\n",
    "\n",
    "        assert len(self.kws) == len(self.embeddings)\n",
    "\n",
    "    def create_embeddings(self):\n",
    "        \"\"\"Create embeddings for all keywords\"\"\"\n",
    "        kws_to_embed = self.kws\n",
    "        embeddings = self._embed_langchain(kws_to_embed)\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def _embed_langchain(self, texts, use_text_to_add=True):\n",
    "        text_to_add = \"\"\n",
    "        if use_text_to_add:\n",
    "            text_to_add = self.text_to_add\n",
    "        return self.embedder.embed_documents([text_to_add + text for text in texts])\n",
    "\n",
    "    def _embed(self, texts, use_text_to_add=True):\n",
    "        text_to_add = \"\"\n",
    "        if use_text_to_add:\n",
    "            text_to_add = self.text_to_add\n",
    "        return openai.Embedding.create(\n",
    "            input=[text_to_add + kw for kw in texts], model=self.model\n",
    "        )\n",
    "\n",
    "    def find_nearest_kw(self, keyword, top_n=1):\n",
    "        \"\"\"Find the nearest keyword to the given keyword\"\"\"\n",
    "        embedding = self._embed_langchain([keyword], use_text_to_add=False)\n",
    "        embedding = np.array(embedding)\n",
    "        distances = np.linalg.norm(self.embeddings - embedding, axis=1)\n",
    "\n",
    "        return [self.kws[i] for i in np.argsort(distances)[:top_n]]\n",
    "\n",
    "    def read_kws(\n",
    "        self,\n",
    "        file,\n",
    "    ):\n",
    "        \"\"\"Read keywords from file\"\"\"\n",
    "        kws = []\n",
    "\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            kws = json.load(f)\n",
    "        return [kw[\"keyword_string\"] for kw in kws]\n",
    "\n",
    "    def load_from_pkl(self, file):\n",
    "        \"\"\"Load embeddings from pickle file\"\"\"\n",
    "        return np.load(file)\n",
    "\n",
    "class BoundingBoxFinderTool(BaseTool):\n",
    "    name = \"bounding_box_finder\"\n",
    "    description = \"useful to find bounding box in min Longitude, min Latitude, max Longitude, max Latitude format for a given location, region, or a landmark. The output is formatted for CMR API.\"\n",
    "    geocoder = opencage_geocoder\n",
    "\n",
    "    def _run(self, tool_input: str) -> str:\n",
    "        \"\"\"Geocode a query (location, region, landmark)\"\"\"\n",
    "        response = self.geocoder.geocode(tool_input, no_annotations=\"1\")\n",
    "        if response:\n",
    "            bounds = response[0][\"bounds\"]\n",
    "            # convert to bbox\n",
    "            bbox = \"{},{},{},{}\".format(\n",
    "                bounds[\"southwest\"][\"lng\"],\n",
    "                bounds[\"southwest\"][\"lat\"],\n",
    "                bounds[\"northeast\"][\"lng\"],\n",
    "                bounds[\"northeast\"][\"lat\"],\n",
    "            )\n",
    "            return f\"bounding_box[]={bbox}\"\n",
    "        return \"Cannot parse the query\"\n",
    "\n",
    "    async def _arun(self, tool_input: str) -> str:\n",
    "        \"\"\"asynchronous call to Geocode a query\"\"\"\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = self.geocoder.geocode(tool_input, no_annotations=\"1\")\n",
    "            if response:\n",
    "                bounds = response[0][\"bounds\"]\n",
    "                # convert to bbox\n",
    "                # bounding_box[]=\n",
    "                bbox = \"{},{},{},{}\".format(\n",
    "                    bounds[\"southwest\"][\"lng\"],\n",
    "                    bounds[\"southwest\"][\"lat\"],\n",
    "                    bounds[\"northeast\"][\"lng\"],\n",
    "                    bounds[\"northeast\"][\"lat\"],\n",
    "                )\n",
    "                return f\"bounding_box[]={bbox}\"\n",
    "\n",
    "            else:\n",
    "                return \"Cannot parse the query\"\n",
    "\n",
    "\n",
    "def geocode(text: str) -> str:\n",
    "    \"\"\"Geocode a query (location, region, or landmark)\"\"\"\n",
    "    response = opencage_geocoder.geocode(text, no_annotations=\"1\")\n",
    "    if response:\n",
    "        bounds = response[0][\"bounds\"]\n",
    "        # convert to bbox\n",
    "        bbox = \"{},{},{},{}\".format(\n",
    "            bounds[\"southwest\"][\"lng\"],\n",
    "            bounds[\"southwest\"][\"lat\"],\n",
    "            bounds[\"northeast\"][\"lng\"],\n",
    "            bounds[\"northeast\"][\"lat\"],\n",
    "        )\n",
    "        return f\"bounding_box[]={bbox}\"\n",
    "\n",
    "    @tool\n",
    "    async def calculate(expression):\n",
    "        \"\"\"Calculate an expression\"\"\"\n",
    "        return eval(expression)\n",
    "\n",
    "\n",
    "class CMRQueryTool(BaseTool):\n",
    "    name = \"cmr_query_api\"\n",
    "    description = \"useful for Querying CMR API based on previous Observations. input is query parameters string\"\n",
    "    base_url = \"https://cmr.earthdata.nasa.gov/search/collections?\"\n",
    "\n",
    "    def _run(self, tool_input: str) -> str:\n",
    "        k: int = 40\n",
    "        \"\"\"Filter a CMR response\"\"\"\n",
    "\n",
    "        if self.base_url in tool_input:\n",
    "            tool_input = tool_input.replace(self.base_url, \"\")\n",
    "        return self.base_url + tool_input\n",
    "\n",
    "    async def _arun(self, tool_input: str) -> str:\n",
    "        \"\"\"asynchronous call to filter a CMR response\"\"\"\n",
    "        return [self._filter_response(tool_input)]\n",
    "\n",
    "gpt_embedder = GPTEmbedder(embeddings_file=\"../data/keyword_embeddings.npy\")\n",
    "\n",
    "class GCMDKeywordSearchTool(BaseTool):\n",
    "    \"\"\"Search for science keyword in GCMD science keyword database. only earth science keywords are allowed, no other keywords are allowed\"\"\"\n",
    "    name = \"gcmd_keyword_search\"\n",
    "    description = \"useful to search for earth science keyword in GCMD database. only earth science keywords and phenomena are allowed as inputs, no other keywords are allowed. The output is formatted for CMR API.\"\n",
    "\n",
    "    def _run(self, tool_input: str) -> str:\n",
    "        \"\"\"Search for a keyword in GCMD\"\"\"\n",
    "    \n",
    "        return self.get_formatted_science_kws(tool_input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_formatted_science_kws(tool_input: str, top_n=5) -> str:\n",
    "        \"\"\"Search for a keyword in GCMD\"\"\"\n",
    "        keywords = [\n",
    "            GCMDKeywordSearchTool().cmr_science_keyword(kw, keyword_pos)\n",
    "            for keyword_pos, kw in enumerate(\n",
    "                gpt_embedder.find_nearest_kw(tool_input, top_n=top_n)\n",
    "            )\n",
    "        ]\n",
    "        if isinstance(keywords, list):\n",
    "            return keywords[0]\n",
    "        return keywords\n",
    "\n",
    "    @staticmethod\n",
    "    def get_science_kws(tool_input: str, top_n=5) -> str:\n",
    "        \"\"\"Search for a keyword in GCMD\"\"\"\n",
    "        return [kw for kw in gpt_embedder.find_nearest_kw(tool_input, top_n=top_n)]\n",
    "\n",
    "    async def _arun(self, tool_input: str) -> str:\n",
    "        \"\"\"Search for a keyword in GCMD\"\"\"\n",
    "        return self.get_formatted_science_kws(tool_input)\n",
    "\n",
    "    @staticmethod\n",
    "    def cmr_science_keyword(keyword_string, keyword_pos):\n",
    "        level_list = [\n",
    "            \"category\",\n",
    "            \"topic\",\n",
    "            \"term\",\n",
    "            \"variable-level-1\",\n",
    "            \"variable-level-2\",\n",
    "            \"variable-level-3\",\n",
    "            \"detailed-variable\",\n",
    "        ]\n",
    "        keyword_list = [key.strip() for key in keyword_string.split(\">\")]\n",
    "\n",
    "        return \"&\".join(\n",
    "            [\n",
    "                rf\"science_keywords[{keyword_pos}][{level_list[i]}]={keyword_list[i].replace(' ', '%20')}\"\n",
    "                for i in range(len(keyword_list))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain\n",
    "\n",
    "Langchain is a library that provides a set of tools to interact with language models, such as GPT-3, and to build agents that can understand and process information, evaluate situations, take appropriate actions, communicate responses, and track ongoing situations. Below is a simple example of how to use the library to implement a ReACT agent.\n",
    "\n",
    "Components used:\n",
    "CustomPromptTemplate - ReACT Prompt class\n",
    "CustomOutputParser - ReACT Output controller class for routing LLM actions\n",
    "Agent - ReACT Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Union\n",
    "\n",
    "from langchain import LLMChain, OpenAI\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleActionAgent,\n",
    "    Tool,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    \"\"\"\n",
    "    This is a custom prompt template that uses the `cmr_template` from `prompts.py`\n",
    "    \"\"\"\n",
    "\n",
    "    template: str\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in self.tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]\n",
    "\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \"\"\"\n",
    "    This is a custom output parser that parses the output of the LLM agent\n",
    "    \"\"\"\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        \n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )\n",
    "\n",
    "\n",
    "class CMRQueryAgent:\n",
    "    \"\"\"\n",
    "    This is a custom agent that uses the `CustomPromptTemplate` and `CustomOutputParser`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.create_tools()\n",
    "        self.tool_names = [tool.name for tool in self.tools]\n",
    "        self.prompt = CustomPromptTemplate(\n",
    "            template=cmr_template,\n",
    "            tools=self.tools,\n",
    "            # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "            # This includes the `intermediate_steps` variable because that is needed\n",
    "            input_variables=[\"input\", \"intermediate_steps\"],\n",
    "        )\n",
    "        self.output_parser = CustomOutputParser()\n",
    "        self.llm_chain = LLMChain(\n",
    "            llm=ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0),\n",
    "            prompt=self.prompt,\n",
    "        )\n",
    "        self.create_agent()\n",
    "\n",
    "    def create_tools(self):\n",
    "        \"\"\"create tools for the agent\"\"\"\n",
    "        self.tools = [\n",
    "            Tool(\n",
    "                name=BoundingBoxFinderTool().name,\n",
    "                description=BoundingBoxFinderTool().description,\n",
    "                func=BoundingBoxFinderTool().run,\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"DateTime Extractor\",\n",
    "                description=\"Extracts time string and converts it to a datetime format\",\n",
    "                func=DatetimeChain().run,\n",
    "            ),\n",
    "            Tool(\n",
    "                name=GCMDKeywordSearchTool().name,\n",
    "                description=GCMDKeywordSearchTool().description,\n",
    "                func=GCMDKeywordSearchTool().run,\n",
    "            ),\n",
    "            Tool(\n",
    "                name=CMRQueryTool().name,\n",
    "                description=CMRQueryTool().description,\n",
    "                func=CMRQueryTool().run,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def create_agent(self):\n",
    "        self.agent = LLMSingleActionAgent(\n",
    "            llm_chain=self.llm_chain,\n",
    "            output_parser=self.output_parser,\n",
    "            stop=[\"\\nObservation:\"],\n",
    "            allowed_tools=self.tool_names,\n",
    "        )\n",
    "        self.agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "            agent=self.agent, tools=self.tools, verbose=True\n",
    "        )\n",
    "\n",
    "    def run_query(self, input_text: str):\n",
    "        return self.agent_executor.run(input_text)\n",
    "\n",
    "query_agent = CMRQueryAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to extract the datetime for the last 5 years, find the bounding box for California, and search for the GCMD science keyword related to landslides and earthquakes.\n",
      "\n",
      "Action: DateTime Extractor\n",
      "Action Input: for the last 5 years\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "start = '2019-03-01T00:00:00Z'\n",
      "end = '2024-03-01T00:00:00Z'\n",
      "temporal = 'temporal[]=' + start + ',' + end\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI have the datetime range for the last 5 years. Now I need to find the bounding box for California.\n",
      "\n",
      "Action: bounding_box_finder\n",
      "Action Input: California\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mbounding_box[]=-124.482003,32.5295236,-114.1307816,42.009499\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI have the bounding box for California. Next, I need to search for the GCMD science keyword related to landslides and earthquakes.\n",
      "\n",
      "Action: gcmd_keyword_search\n",
      "Action Input: landslides earthquakes\u001b[0m\n",
      "\n",
      "Observation:\u001b[38;5;200m\u001b[1;3mscience_keywords[0][category]=EARTH%20SCIENCE&science_keywords[0][topic]=HUMAN%20DIMENSIONS&science_keywords[0][term]=NATURAL%20HAZARDS&science_keywords[0][variable-level-1]=LANDSLIDES\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now have the GCMD science keyword related to landslides and earthquakes. I have all the information for the CMR query.\n",
      "\n",
      "Action: cmr_query_api\n",
      "Action Input: temporal[]=2019-03-01T00:00:00Z,2024-03-01T00:00:00Z&bounding_box[]=-124.482003,32.5295236,-114.1307816,42.009499&science_keywords[0][category]=EARTH%20SCIENCE&science_keywords[0][topic]=HUMAN%20DIMENSIONS&science_keywords[0][term]=NATURAL%20HAZARDS&science_keywords[0][variable-level-1]=LANDSLIDES\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mhttps://cmr.earthdata.nasa.gov/search/collections?temporal[]=2019-03-01T00:00:00Z,2024-03-01T00:00:00Z&bounding_box[]=-124.482003,32.5295236,-114.1307816,42.009499&science_keywords[0][category]=EARTH%20SCIENCE&science_keywords[0][topic]=HUMAN%20DIMENSIONS&science_keywords[0][term]=NATURAL%20HAZARDS&science_keywords[0][variable-level-1]=LANDSLIDES\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mFinal Answer: Provide the link from cmr_query_api. If a link is not available, suggest the user how to modify the query to get the link.\n",
      "\n",
      "Final Answer: To monitor landslides caused by earthquakes in California for the last 5 years, you can use the following CMR API query link: [https://cmr.earthdata.nasa.gov/search/collections?temporal[]=2019-03-01T00:00:00Z,2024-03-01T00:00:00Z&bounding_box[]=-124.482003,32.5295236,-114.1307816,42.009499&science_keywords[0][category]=EARTH%20SCIENCE&science_keywords[0][topic]=HUMAN%20DIMENSIONS&science_keywords[0][term]=NATURAL%20HAZARDS&science_keywords[0][variable-level-1]=LANDSLIDES](https://cmr.earthdata.nasa.gov/search/collections?temporal[]=2019-03-01T00:00:00Z,2024-03-01T00:00:00Z&bounding_box[]=-124.482003,32.5295236,-114.1307816,42.009499&science_keywords[0][category]=EARTH%20SCIENCE&science_keywords[0][topic]=HUMAN%20DIMENSIONS&science_keywords[0][term]=NATURAL%20HAZARDS&science_keywords[0][variable-level-1]=LANDSLIDES).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "To monitor landslides caused by earthquakes in California for the last 5 years, you can use the following CMR API query link: [https://cmr.earthdata.nasa.gov/search/collections?temporal[]=2019-03-01T00:00:00Z,2024-03-01T00:00:00Z&bounding_box[]=-124.482003,32.5295236,-114.1307816,42.009499&science_keywords[0][category]=EARTH%20SCIENCE&science_keywords[0][topic]=HUMAN%20DIMENSIONS&science_keywords[0][term]=NATURAL%20HAZARDS&science_keywords[0][variable-level-1]=LANDSLIDES](https://cmr.earthdata.nasa.gov/search/collections?temporal[]=2019-03-01T00:00:00Z,2024-03-01T00:00:00Z&bounding_box[]=-124.482003,32.5295236,-114.1307816,42.009499&science_keywords[0][category]=EARTH%20SCIENCE&science_keywords[0][topic]=HUMAN%20DIMENSIONS&science_keywords[0][term]=NATURAL%20HAZARDS&science_keywords[0][variable-level-1]=LANDSLIDES).\n"
     ]
    }
   ],
   "source": [
    "query= \"data to monitor landslides caused by earthquakes in california for the last 5 years.\"\n",
    "print(\n",
    "    query_agent.run_query(query)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The query \"What is osmosis?\" is not a valid CMR query. It seems to be a general science question rather than a query related to Earth science data or phenomena that would be found in the CMR database. The CMR (Common Metadata Repository) is used for Earth science satellite observations, and \"osmosis\" is a biological/chemical process that does not directly relate to the type of data stored in CMR. Therefore, I cannot proceed with the usual steps of finding a bounding box, extracting datetime, or searching for a GCMD science keyword.\n",
      "\n",
      "Final Answer: The query \"What is osmosis?\" does not correspond to a CMR query. If you are looking for satellite observations or Earth science data related to a specific phenomenon, location, or time period, please provide a query that includes those details. For example, you could ask for satellite data related to \"sea surface temperature in the Gulf of Mexico in July 2020\" or \"precipitation data for the Amazon rainforest in 2021.\" If you need information on the process of osmosis, you may want to consult a biology or chemistry resource instead.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The query \"What is osmosis?\" does not correspond to a CMR query. If you are looking for satellite observations or Earth science data related to a specific phenomenon, location, or time period, please provide a query that includes those details. For example, you could ask for satellite data related to \"sea surface temperature in the Gulf of Mexico in July 2020\" or \"precipitation data for the Amazon rainforest in 2021.\" If you need information on the process of osmosis, you may want to consult a biology or chemistry resource instead.\n"
     ]
    }
   ],
   "source": [
    "query= \"What is osmosis?\"\n",
    "print(\n",
    "    query_agent.run_query(query)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
